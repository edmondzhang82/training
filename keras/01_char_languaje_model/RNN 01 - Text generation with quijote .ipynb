{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a RNN model to text generation\n",
    "- RNN model at character level\n",
    "    - Input: n character previous\n",
    "    - Output: next character\n",
    "    - Model LSTM\n",
    "- Use 'El Quijote' to train the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = '/home/ubuntu/data/training/keras/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and generate sequences\n",
    "\n",
    "Download quijote from guttenberg project\n",
    "\n",
    "\n",
    "wget http://www.gutenberg.org/cache/epub/2000/pg2000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2198927\n",
      "Chars list:  ['\\n', '\\r', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x81', '\\x89', '\\x8d', '\\x91', '\\x93', '\\x9a', '\\xa0', '\\xa1', '\\xa9', '\\xab', '\\xad', '\\xaf', '\\xb1', '\\xb3', '\\xb9', '\\xba', '\\xbb', '\\xbc', '\\xbf', '\\xc2', '\\xc3', '\\xef']\n",
      "total chars: 80\n"
     ]
    }
   ],
   "source": [
    "#Read book\n",
    "text = open(path + \"pg2000.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('Chars list: ', chars)\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "#Dictionaries to convert char to num & num to char\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 732869\n",
      "e nombre el río taj - o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "# One sentence of length 20 for each 3 characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(300, len(text) - maxlen, step): #Start in line 30 to exclude Gutenberg header.\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "print(sentences[4996], '-', next_chars[4996])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "X shape:  (732869, 20, 80)\n",
      "y shape:  (732869, 80)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X: One row by sentence\n",
    "    in each row a matrix of bool 0/1 of dim length_sentence x num_chars coding the sentence. Dummy variables\n",
    "y: One row by sentence\n",
    "    in each row a vector of bool of lengt num_chars with 1 in the next char position\n",
    "'''\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print('X shape: ',X.shape)\n",
    "print('y shape: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "prev (InputLayer)                (None, 20, 80)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 20, 512)       1214464     prev[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 512)           2099200     lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 80)            41040       lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 3354704\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "print('Build model 1')\n",
    "seq_prev_input = Input(shape=(maxlen, len(chars)), name='prev') \n",
    "                \n",
    "# apply forwards LSTM\n",
    "forwards1 = LSTM(512, dropout_W=0.3, dropout_U=0.3, return_sequences=True)(seq_prev_input)\n",
    "\n",
    "forwards2 = LSTM(512, dropout_W=0.3, dropout_U=0.3, return_sequences=False)(forwards1)\n",
    "\n",
    "output = Dense(len(chars), activation='softmax')(forwards2)\n",
    "\n",
    "model1 = Model(input=seq_prev_input, output=output)\n",
    "model1.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"268pt\" viewBox=\"0.00 0.00 120.00 268.00\" width=\"120pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 264)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-264 116,-264 116,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140666222649488 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140666222649488</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-223 -0.5,-259 112.5,-259 112.5,-223 -0.5,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-237.3\">prev (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140665749659536 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140665749659536</title>\n",
       "<polygon fill=\"none\" points=\"4,-149 4,-185 108,-185 108,-149 4,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-163.3\">lstm_1 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140666222649488&#45;&gt;140665749659536 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140666222649488-&gt;140665749659536</title>\n",
       "<path d=\"M56,-222.937C56,-214.807 56,-204.876 56,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-195.441 56,-185.441 52.5001,-195.441 59.5001,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140666223116688 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140666223116688</title>\n",
       "<polygon fill=\"none\" points=\"4,-75 4,-111 108,-111 108,-75 4,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-89.3\">lstm_2 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140665749659536&#45;&gt;140666223116688 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140665749659536-&gt;140666223116688</title>\n",
       "<path d=\"M56,-148.937C56,-140.807 56,-130.876 56,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-121.441 56,-111.441 52.5001,-121.441 59.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140664130012112 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140664130012112</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-1 2.5,-37 109.5,-37 109.5,-1 2.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-15.3\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140666223116688&#45;&gt;140664130012112 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140666223116688-&gt;140664130012112</title>\n",
       "<path d=\"M56,-74.937C56,-66.8072 56,-56.8761 56,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-47.4406 56,-37.4407 52.5001,-47.4407 59.5001,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the model\n",
    "#Plot the model graph\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model1).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600000 samples, validate on 132869 samples\n",
      "Epoch 1/30\n",
      "600000/600000 [==============================] - 625s - loss: 2.3064 - acc: 0.3143 - val_loss: 1.9490 - val_acc: 0.4013\n",
      "Epoch 2/30\n",
      "600000/600000 [==============================] - 694s - loss: 1.8458 - acc: 0.4247 - val_loss: 1.7759 - val_acc: 0.4594\n",
      "Epoch 3/30\n",
      "600000/600000 [==============================] - 694s - loss: 1.5572 - acc: 0.5090 - val_loss: 1.5789 - val_acc: 0.5218\n",
      "Epoch 6/30\n",
      " 18432/600000 [..............................] - ETA: 626s - loss: 1.5344 - acc: 0.5137"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c032a011fb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model1.fit(X[:600000], y[:600000], batch_size=512, nb_epoch=30,\n\u001b[0;32m----> 3\u001b[0;31m            validation_data=(X[600000:], y[600000:]))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "history = model1.fit(X[:600000], y[:600000], batch_size=512, nb_epoch=30,\n",
    "           validation_data=(X[600000:], y[600000:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train on 600000 samples, validate on 132869 samples\n",
    "Epoch 1/30\n",
    "600000/600000 [==============================] - 523s - loss: 2.2971 - acc: 0.3154 - val_loss: 1.9305 - val_acc: 0.4111\n",
    "Epoch 2/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.8107 - acc: 0.4357 - val_loss: 1.7215 - val_acc: 0.4805\n",
    "Epoch 3/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.6351 - acc: 0.4875 - val_loss: 1.6226 - val_acc: 0.5123\n",
    "Epoch 4/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.5340 - acc: 0.5168 - val_loss: 1.5604 - val_acc: 0.5306\n",
    "Epoch 5/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.4689 - acc: 0.5361 - val_loss: 1.5244 - val_acc: 0.5443\n",
    "Epoch 6/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.4232 - acc: 0.5494 - val_loss: 1.5053 - val_acc: 0.5508\n",
    "Epoch 7/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.3890 - acc: 0.5596 - val_loss: 1.4823 - val_acc: 0.5579\n",
    "Epoch 8/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.3618 - acc: 0.5672 - val_loss: 1.4643 - val_acc: 0.5625\n",
    "Epoch 9/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.3409 - acc: 0.5730 - val_loss: 1.4587 - val_acc: 0.5667\n",
    "Epoch 10/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.3231 - acc: 0.5784 - val_loss: 1.4466 - val_acc: 0.5690\n",
    "Epoch 11/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.3084 - acc: 0.5819 - val_loss: 1.4398 - val_acc: 0.5736\n",
    "Epoch 12/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2954 - acc: 0.5864 - val_loss: 1.4360 - val_acc: 0.5740\n",
    "Epoch 13/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2839 - acc: 0.5885 - val_loss: 1.4296 - val_acc: 0.5776\n",
    "Epoch 14/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2751 - acc: 0.5913 - val_loss: 1.4275 - val_acc: 0.5785\n",
    "Epoch 15/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2645 - acc: 0.5944 - val_loss: 1.4230 - val_acc: 0.5794\n",
    "Epoch 16/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2578 - acc: 0.5963 - val_loss: 1.4182 - val_acc: 0.5816\n",
    "Epoch 17/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2508 - acc: 0.5988 - val_loss: 1.4202 - val_acc: 0.5818\n",
    "Epoch 18/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2455 - acc: 0.6005 - val_loss: 1.4151 - val_acc: 0.5812\n",
    "Epoch 19/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2394 - acc: 0.6017 - val_loss: 1.4133 - val_acc: 0.5836\n",
    "Epoch 20/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2332 - acc: 0.6037 - val_loss: 1.4099 - val_acc: 0.5848\n",
    "Epoch 21/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.2288 - acc: 0.6051 - val_loss: 1.4164 - val_acc: 0.5837\n",
    "Epoch 22/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2247 - acc: 0.6057 - val_loss: 1.4102 - val_acc: 0.5861\n",
    "Epoch 23/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.2215 - acc: 0.6067 - val_loss: 1.4080 - val_acc: 0.5873\n",
    "Epoch 24/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2167 - acc: 0.6078 - val_loss: 1.4099 - val_acc: 0.5855\n",
    "Epoch 25/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2124 - acc: 0.6097 - val_loss: 1.4050 - val_acc: 0.5876\n",
    "Epoch 26/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2111 - acc: 0.6101 - val_loss: 1.4105 - val_acc: 0.5868\n",
    "Epoch 27/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2059 - acc: 0.6116 - val_loss: 1.4027 - val_acc: 0.5879\n",
    "Epoch 28/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2026 - acc: 0.6122 - val_loss: 1.4048 - val_acc: 0.5868\n",
    "Epoch 29/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.1990 - acc: 0.6138 - val_loss: 1.4090 - val_acc: 0.5887\n",
    "Epoch 30/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.1969 - acc: 0.6139 - val_loss: 1.4053 - val_acc: 0.5889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-422066002d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "'''\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "json_string = model1.to_json()\n",
    "open(path + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model1.save_weights(path + 'models/w_' + model_name + '.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "model1 = model_from_json(open(path + 'models/mdl_' + model_name + '.json').read())\n",
    "model1.load_weights(path + 'models/w_' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "\n",
    "\n",
    "def sample(a, diversity=1.0):\n",
    "    '''\n",
    "    helper function to sample an index from a probability array\n",
    "    - Diversity control the level of randomless\n",
    "    '''\n",
    "    a = np.log(a) / diversity\n",
    "    a = np.exp(a) / np.sum(np.exp(a), axis=0)\n",
    "    a /= np.sum(a+0.0000001) #Precission error\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def generate_text(sentence, diversity, current_model, num_char=400):\n",
    "    sentence_init = sentence\n",
    "    generated = ''\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        preds = current_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print()\n",
    "    print('DIVERSITY: ',diversity)\n",
    "    print(sentence_init + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIVERSITY:  0.2\n",
      "mire vuestra merced que está en la memoria de la mano de la mano de la mano, y a lo menos que en la cabeza de la mano, sino que después de haber de haber de contar la vida de la mano de la mano de mi señora dulcinea del toboso, y el cura que el más deseo que le había de ser el mundo de la cabeza de la cabeza, y aun en la misma mano y de los demás de la mano de los ojos de los caballeros andantes que en la mitad\n",
      "\n",
      "DIVERSITY:  0.5\n",
      "mire vuestra merced dicen que se le pareció que un poco se le parecía, que no podía ser cosa de los encubiertos y despedirme del mundo, y que está agravio de los presentes, y de los molineros del toboso, a la señora dulcinea del toboso, sino que no es muy bueno. andando esto,\n",
      "volviendo a don quijote y sancho en la mano, y de aquélla que allí juntase.\n",
      "\n",
      "-no es eso -respondió el cura-: ¿por el mesmo se estim\n",
      "\n",
      "DIVERSITY:  1\n",
      "mire vuestra merced señor don bernado, y, con otro don quijote sancho, se le había parecía buen segundo, y volveré con alguna parte.\n",
      "\n",
      "no debe de ser grande apearse otra\n",
      "cosa que de los demás debidos mósicos gaulanos, y luego la duquesa, pero no hallé sobre los cuadrilleros antes que tiene por los hombros del duque y con estar entonces como un letre muley que era menester: sólo quiero que sea frefentando la\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "mire vuestra merced aquí es otra\n",
      " anochecina.\n",
      "\n",
      "-pues, dogna señor, dar, no\n",
      "pudo todas las cruzan, ya se me arraja, cuando\n",
      "más, que sancho quedaramos; que a aquel primero sobre aquellos honres con odejas, y preguntáronlos los caballeros?\n",
      "\n",
      "y, decía que es trato, diciendo:\n",
      "\n",
      "cuardo esto me costábemos;\n",
      "   ya leta o enojo a un caballo un lacagio prometido, a\n",
      "luscinda, y él fue como sus manos quién dillam\n",
      "\n",
      "DIVERSITY:  0.2\n",
      "de lo que sucedió a la mano de la mano de los demás de los ojos de la mesma cosa, y el deseo de la mano de la mano de la mano de la mano de la mano de la cabeza, y en la mesma historia de la mano de la mano de la mano, y que estaba en la mitad de la mano y de los demás de los ojos de los demás de los demás de la mujer de la mano de los caballeros andantes que el modo que en la mitad del caballero de la mano, y l\n",
      "\n",
      "DIVERSITY:  0.5\n",
      "de lo que sucedió a don fernando, dijo:\n",
      "\n",
      "-no es la mejor que hacer otra cosas de manera que no se hallará\n",
      "en el mundo que con mucha presteza y los brazos a la cabeza de las manos, que no este mal\n",
      "nombre de mi padre, en la gran cual no podía\n",
      "dejar de mandar y a los entretenidos, y después de haber puesto en la cabeza en la cabeza, como yo tengo de ser costumbre de mi razón, y de la más nueva de la cabeza, p\n",
      "\n",
      "DIVERSITY:  1\n",
      "de lo que sucedió aunque había curado del\n",
      "molidor. este don quijote -respondió sancho-, para\n",
      "mediaña que he dicho, que suele ser hermosura que confuso sois yo que lo dijo que en aquel mal se pidieron decir que\n",
      "huyen suplico\n",
      "dorotea del que aquel mal\n",
      "tierra; y así, dejaba de ser lugares de su grande espada, pues no es esto, se llegó a albarda, aunque dijo la doncella\n",
      "que no podía menester cosa mucha\n",
      "vece\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "de lo que sucedió a cumplir los antiguos contornos con\n",
      "sus indiciones que esitan fueron, la su profesión! iba sancho a un péraro, de preguntas comodiantes, y camino a movimiento,\n",
      "diciendo:\n",
      "\n",
      "-doradme, cuando he contado entre encantador oílo déjemos\n",
      "mísimo valdo, dedota el viaje como ellos\n",
      "podían pesadumbre en poco un días o leyendado un tal sílo por este grito? ¿quién\n",
      "vio que afecha estaban; y, puest\n",
      "\n",
      "DIVERSITY:  0.2\n",
      "de allí a poco comenzó a su deseo de su caballero andante, que no la había de ser con los deseos de la mano, y los demás de los demás de los demás de la cabeza, y que en la mitad del cabrero, y al modo de los demás de la mano de los demás de la mano de los cuatro del mundo.\n",
      "\n",
      "-¿qué es lo que dicen que estaban en la mano de la mano de la mano de la cabeza, y los dos le dijo:\n",
      "\n",
      "-¿qué mal se ha de allí a \n",
      "\n",
      "DIVERSITY:  0.5\n",
      "de allí a poco comenzó a su casa, y aun a la mujer de la mano de la deseo de la duquesa y por los demás de la cabeza, y no le pareció que había de ser el nombre de la belleza de los de la mano, vio el cura que el que le había de tener la cabeza y desengañado me diga.\n",
      "\n",
      "-yo le digo dorotea -respondió sancho-, que estaba con la mitad de las\n",
      "rodrigas de los cuatro días que me despedirían en la memoria del ca\n",
      "\n",
      "DIVERSITY:  1\n",
      "de allí a poco comer, con todo\n",
      "lo que vuestra merced le ayude ni hubiera\n",
      "hecho. conocimiento que cuando en\n",
      "este punto o salir a las señoras y límelas de dos seis\n",
      "prendistes no pensaban en el pulto\n",
      "del honesto, con un aire -dijo el cura-, la que tengo discreta en\n",
      "que no se le aguardaba, aunque dé a los diestros a\n",
      "lo que tenmo, y en el aire y señores, y será decir que en una de las entrañas angólatas a l\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "de allí a poco comenzó a entender que yo le vea un bien alguno hay nadie en salir a vuestra incomodida.\n",
      "\n",
      "a esto que oo granjé como por su\n",
      "muchujeres y niego en un sentido, hóralme hubieran de arcabucendo; el valeroso dejando, de ver más beñita y de los árboles como la\n",
      "leyesen, a tenía casa para sobresatino y le debía\n",
      "venir que aun no era la más señora acómomo, cual, así como es elandro.\n",
      "\n",
      "-tropizco\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = 'mire vuestra merced '\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de lo que sucedió a'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de allí a poco come'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "mire vuestra merced decís, y que se le pareció que en la cabeza de la cabeza, y el caballero del caballero de la cabeza, y los demás de los demás de los demás de los demás de la mano de la mujer de la mano de la mano, y aun a su señora dulcinea del toboso, y el cura que el caballero de la mano que le pareció que estaba en la misma cosa que en la mitad del caballero de la mano, se le dijo:\n",
    "\n",
    "-no sé -respondi\n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "mire vuestra merced que no está en la cabeza. pero, en efeto, pues todo aquello que está en el mundo que cada uno debía\n",
    "de ser con la misma sierra parte de la muerte de la mano, con todo el mundo me la conoció, que tenía por el primero que están el rostro en las manos, y al señor don quijote -respondió sancho-, porque en la puerta de los sucesos del buen estado de la desencantada de los ojos.\n",
    "\n",
    "-¿qué mal \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "mire vuestra merced que, aunque, desdicho y tiempo viene, a\n",
    "cuya cabeza destos tres, los informaciones que dejara de serle, que me fueron? ¿admirado,\n",
    "\n",
    "y, creyendo que me va y enfermo. y esto que tienen entonces las requiebros que algunos limpios en un ampeoso como si improvisentes en sus insimulables y en los míos al que el honesto, en la mano de mucho premio y don quijote fingióno los dos o sabidores, y,\n",
    "acom\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "mire vuestra merced paso que no sa cluero-. subió, señor,\n",
    "le hubiera vuelto el duque, que pica, yo fue pose�ría de guardar cierto. para los demás, esperando la misma tragua debe de haberlas hallado su santa hijo ni debían para mí, porque yo hay de platar pre subir tú turba -dijo el deleitable-; otras porturas, sino como alabanzas y\n",
    "comedimientos puciese\n",
    "los días de lo que von mirado después de\n",
    "visión de\n",
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "de lo que sucedió a la mano de la mano de la mano de los ojos de la mano de la mano de la mano, y aun más que se le dijese la mano de la mano y en la mitad del caballero del caballero de la mano de la mano, y que el parte de la mano, y que en la mitad del caballero de la mano, sino a la puerta de la mano de la mano de la mano de los demás de la cabeza, y el cura y la cabeza de la mano y en la cabeza de la cabeza, \n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "de lo que sucedió a camila, por ser tan alta de la mano y en voz brazo? ¿qué es lo que pudiera, señor don quijote que en las fermosuras que después que le sacarán con don quijote había de ser la duquesa, la cual no le había de ser muy buena como gausa, y si este deseo de ser mejor que en la cabeza está a los dos de la mano, y su amo no le puede dar a su casa por los manos de mano, diciendo:\n",
    "\n",
    "-pues, ¿qué \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "de lo que sucedió a las más faltas cuentan haciendo:\n",
    "\n",
    "-�qcorrían por esto, bueno -respondió cómo está aquel mano traía furia por ella estajo\n",
    "más que andaba y fingión de sus apartieron de modo que no\n",
    "hay vasto qué hizo con galdáis que soy sin duda, duque ni en la más\n",
    "buena gran señora dulcinea; y así lo han don quijote y no bastaba junto a nuestra\n",
    "señora dulcinea, ahora\n",
    "la entienda, el aposento a\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "de lo que sucedió al\n",
    "admiración, dijo:\n",
    "\n",
    "-eso me esplevo en razón encantada, y su venimo tiempo, que pasaba tan hirtoria. es\n",
    "\n",
    "don quijote, le dijo:\n",
    "\n",
    "y cuando jamás:\n",
    "  si ya entienden en mi padre desde aquí vean fuerza, como yo\n",
    "costa yo he oído decir, el rey\n",
    "\n",
    "vención que ésto, que lo més comenzó a vuestra merced colgaré por la orden y parece que\n",
    "pudieron semplarse. el cual, si de la mono.\n",
    "acudi�\n",
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "de allí a poco comenzó a su caballero andante, que en la más hermosa de la mano, y el cura que el mundo tenía con el cura y el de la mano de la cabeza de la mano de la mano de la mano de la mano de la cabeza, y a los demás de los cuatro de la mano de la mano de la mano y en la mitad del caballero de la cabeza, y le dijo:\n",
    "\n",
    "-¡oh sancho -dijo el cura-, que no se le habían de ser manos de los demás de los de la\n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "de allí a poco comenzó a la vida de la mano de\n",
    "arriba al mundo. pero, con todo eso, ha de ser el rostro de las linajes de su escudero. por el rey en el mundo de la industria que en su caballero andante; y, aunque se volvió a camila y de la mano de la muerte de mi cabeza? y así, como el tal caballero andante, que los demás juramentos, y con la mitad del toboso, y así, por decir que os son de allí a los deseos \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "de allí a poco comenzó\n",
    "a dos crazos de entender que tratar la nueva al desde nuevas andantes de solos con los detros donde me hubieran\n",
    "de subir la sumiera y rabia la duquesa\n",
    "   a un hacer con un gato, que le\n",
    "dijo juntar la locura para su\n",
    "amo, para que quisieron decir alguna, vino\n",
    "todas aquellos demás caballeros. pero, sancho, tanto, viendo camila la primero tiene: prodición\n",
    "que yo le dio caminar las belloz\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "de allí a poco comer. otros días se le pidía hablar de cerra\n",
    "   que el gate predice\n",
    "y otras puntas del cordel bestia.\n",
    "\n",
    "-yo no por eso, decaría sobre la venta, porque él saslos demás sin él que\n",
    "llevase a buscar de la suma, sancho milático, cuando posían los zogados. y si así, mi rendido a\n",
    "cuerpo, ni en llopar salió el baece-, que el hábísimo que viene por\n",
    "los tratas y tontos que sean, y el de los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

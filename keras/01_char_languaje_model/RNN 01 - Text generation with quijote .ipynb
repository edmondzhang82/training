{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a RNN model to text generation\n",
    "- RNN model at character level\n",
    "    - Input: n character previous\n",
    "    - Output: next character\n",
    "    - Model LSTM\n",
    "- Use 'El Quijote' to train the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, cuDNN 5103)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:599: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# Header\n",
    "path = '/home/ubuntu/data/training/keras/'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and generate sequences\n",
    "\n",
    "Download quijote from guttenberg project\n",
    "\n",
    "\n",
    "wget http://www.gutenberg.org/cache/epub/2000/pg2000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 2198927)\n",
      "('total chars:', 80)\n"
     ]
    }
   ],
   "source": [
    "text = open(path + \"pg2000.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "#Dictionaries to convert char to num & num to char\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\x81', 1: '@', 2: '\\x89', 3: '\\xad', 4: '\\xba', 5: '\\n', 6: '\\r', 7: '\\x91', 8: '\\x93', 9: '\\xef', 10: '\\x9a', 11: '/', 12: '\\xa1', 13: ' ', 14: '#', 15: ')', 16: '%', 17: '$', 18: \"'\", 19: '\\xa9', 20: '(', 21: '\\xab', 22: '*', 23: '-', 24: ',', 25: '\\xaf', 26: '.', 27: '1', 28: '0', 29: '\\xb3', 30: '2', 31: '5', 32: '4', 33: '7', 34: '6', 35: '9', 36: '8', 37: '\\xbb', 38: ':', 39: '\\xbc', 40: '\\xbf', 41: '?', 42: '!', 43: '\\xc3', 44: '\\xc2', 45: '\\xa0', 46: '\\x8d', 47: '3', 48: '\\xb9', 49: '\"', 50: '[', 51: ']', 52: ';', 53: '\\xb1', 54: 'a', 55: 'c', 56: 'b', 57: 'e', 58: 'd', 59: 'g', 60: 'f', 61: 'i', 62: 'h', 63: 'k', 64: 'j', 65: 'm', 66: 'l', 67: 'o', 68: 'n', 69: 'q', 70: 'p', 71: 's', 72: 'r', 73: 'u', 74: 't', 75: 'w', 76: 'v', 77: 'y', 78: 'x', 79: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print indices_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 732869)\n",
      "e nombre el r√≠o taj - o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "# One sentence of length 20 for each 3 characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(300, len(text) - maxlen, step): #Start in line 30 to exclude Gutenberg header.\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "print sentences[4996], '-', next_chars[4996]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "('X shape: ', (732869, 20, 80))\n",
      "('y shape: ', (732869, 80))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X: One row by sentence\n",
    "    in each row a matrix of bool 0/1 of dim length_sentence x num_chars coding the sentence. Dummy variables\n",
    "y: One row by sentence\n",
    "    in each row a vector of bool of lengt num_chars with 1 in the next char position\n",
    "'''\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print('X shape: ',X.shape)\n",
    "print('y shape: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "('X shape: ', (732869, 20, 80))\n",
      "('y shape: ', (732869,))\n"
     ]
    }
   ],
   "source": [
    "#Export sequiences to hdf5 to model in torch\n",
    "\n",
    "print('Vectorization...')\n",
    "X_num = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.uint8)\n",
    "y_num = np.zeros(len(sentences), dtype=np.uint8)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_num[i, t, char_indices[char]] = 1\n",
    "    y_num[i] = char_indices[next_chars[i]]\n",
    "\n",
    "print('X shape: ',X_num.shape)\n",
    "print('y shape: ',y_num.shape)    \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] 57\n"
     ]
    }
   ],
   "source": [
    "print X_num[2], y_num[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save depurated characters to hdf5\n",
    "import h5py\n",
    "\n",
    "hdf5_f = h5py.File(path + \"sequences20_quijote.hdf5\",mode='a')\n",
    "\n",
    "if \"X\" in hdf5_f:\n",
    "    del hdf5_f[\"X\"]\n",
    "hdf5_f.create_dataset(\"X\", data = X_num) \n",
    "\n",
    "if \"y\" in hdf5_f:\n",
    "    del hdf5_f[\"y\"]\n",
    "hdf5_f.create_dataset(\"y\", data = y_num)\n",
    "\n",
    "hdf5_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "prev (InputLayer)                (None, 20, 80)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 20, 512)       1214464     prev[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 20, 512)       0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 512)           2099200     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 80)            41040       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3354704\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "print('Build model 1')\n",
    "seq_prev_input = Input(shape=(maxlen, len(chars)), name='prev') \n",
    "                \n",
    "# apply forwards LSTM\n",
    "forwards1 = LSTM(512, return_sequences=True)(seq_prev_input)\n",
    "dp1 = Dropout(0.25)(forwards1)\n",
    "\n",
    "forwards2 = LSTM(512, return_sequences=False)(dp1)\n",
    "dp2 = Dropout(0.5)(forwards2)\n",
    "\n",
    "output = Dense(len(chars), activation='softmax')(dp2)\n",
    "\n",
    "model1 = Model(input=seq_prev_input, output=output)\n",
    "model1.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"416pt\" viewBox=\"0.00 0.00 138.00 416.00\" width=\"138pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 412)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-412 134,-412 134,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139702264838416 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139702264838416</title>\n",
       "<polygon fill=\"none\" points=\"8.5,-371 8.5,-407 121.5,-407 121.5,-371 8.5,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-385.3\">prev (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139702264838288 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139702264838288</title>\n",
       "<polygon fill=\"none\" points=\"13,-297 13,-333 117,-333 117,-297 13,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-311.3\">lstm_1 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 139702264838416&#45;&gt;139702264838288 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139702264838416-&gt;139702264838288</title>\n",
       "<path d=\"M65,-370.937C65,-362.807 65,-352.876 65,-343.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"68.5001,-343.441 65,-333.441 61.5001,-343.441 68.5001,-343.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139702264274640 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139702264274640</title>\n",
       "<polygon fill=\"none\" points=\"0,-223 0,-259 130,-259 130,-223 0,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-237.3\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 139702264838288&#45;&gt;139702264274640 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139702264838288-&gt;139702264274640</title>\n",
       "<path d=\"M65,-296.937C65,-288.807 65,-278.876 65,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"68.5001,-269.441 65,-259.441 61.5001,-269.441 68.5001,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139702260875472 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139702260875472</title>\n",
       "<polygon fill=\"none\" points=\"13,-149 13,-185 117,-185 117,-149 13,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-163.3\">lstm_2 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 139702264274640&#45;&gt;139702260875472 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139702264274640-&gt;139702260875472</title>\n",
       "<path d=\"M65,-222.937C65,-214.807 65,-204.876 65,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"68.5001,-195.441 65,-185.441 61.5001,-195.441 68.5001,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139702260795344 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139702260795344</title>\n",
       "<polygon fill=\"none\" points=\"0,-75 0,-111 130,-111 130,-75 0,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-89.3\">dropout_2 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 139702260875472&#45;&gt;139702260795344 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139702260875472-&gt;139702260795344</title>\n",
       "<path d=\"M65,-148.937C65,-140.807 65,-130.876 65,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"68.5001,-121.441 65,-111.441 61.5001,-121.441 68.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139705501193296 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139705501193296</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-1 11.5,-37 118.5,-37 118.5,-1 11.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-15.3\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139702260795344&#45;&gt;139705501193296 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139702260795344-&gt;139705501193296</title>\n",
       "<path d=\"M65,-74.937C65,-66.8072 65,-56.8761 65,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"68.5001,-47.4406 65,-37.4407 61.5001,-47.4407 68.5001,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the model\n",
    "#Plot the model graph\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model1).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit model\n",
    "history = model1.fit(X[:600000], y[:600000], batch_size=256, nb_epoch=30,\n",
    "           validation_data=(X[600000:], y[600000:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build model 1\n",
    "Train on 600000 samples, validate on 182592 samples\n",
    "Epoch 1/30\n",
    "600000/600000 [==============================] - 487s - loss: 1.9885 - acc: 0.4203 - val_loss: 1.6397 - val_acc: 0.5098\n",
    "Epoch 2/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.5699 - acc: 0.5284 - val_loss: 1.4750 - val_acc: 0.5557\n",
    "Epoch 3/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.4520 - acc: 0.5609 - val_loss: 1.4135 - val_acc: 0.5743\n",
    "Epoch 4/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3890 - acc: 0.5785 - val_loss: 1.3771 - val_acc: 0.5831\n",
    "Epoch 5/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3439 - acc: 0.5908 - val_loss: 1.3532 - val_acc: 0.5908\n",
    "Epoch 6/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3109 - acc: 0.5994 - val_loss: 1.3413 - val_acc: 0.5933\n",
    "Epoch 7/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2844 - acc: 0.6066 - val_loss: 1.3297 - val_acc: 0.5976\n",
    "Epoch 8/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2618 - acc: 0.6122 - val_loss: 1.3234 - val_acc: 0.6006\n",
    "Epoch 9/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2418 - acc: 0.6176 - val_loss: 1.3203 - val_acc: 0.6026\n",
    "Epoch 10/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2245 - acc: 0.6222 - val_loss: 1.3204 - val_acc: 0.6052\n",
    "Epoch 11/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.2076 - acc: 0.6267 - val_loss: 1.3223 - val_acc: 0.6057\n",
    "Epoch 12/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1936 - acc: 0.6308 - val_loss: 1.3190 - val_acc: 0.6068\n",
    "Epoch 13/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1795 - acc: 0.6348 - val_loss: 1.3223 - val_acc: 0.6066\n",
    "Epoch 14/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1672 - acc: 0.6379 - val_loss: 1.3317 - val_acc: 0.6071\n",
    "Epoch 15/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1563 - acc: 0.6410 - val_loss: 1.3220 - val_acc: 0.6063\n",
    "Epoch 16/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1443 - acc: 0.6439 - val_loss: 1.3279 - val_acc: 0.6070\n",
    "Epoch 17/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1314 - acc: 0.6467 - val_loss: 1.3320 - val_acc: 0.6080\n",
    "Epoch 18/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1236 - acc: 0.6494 - val_loss: 1.3453 - val_acc: 0.6085\n",
    "Epoch 19/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1108 - acc: 0.6533 - val_loss: 1.3426 - val_acc: 0.6088\n",
    "Epoch 20/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1030 - acc: 0.6551 - val_loss: 1.3536 - val_acc: 0.6090\n",
    "Epoch 21/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0923 - acc: 0.6573 - val_loss: 1.3491 - val_acc: 0.6071\n",
    "Epoch 22/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0814 - acc: 0.6599 - val_loss: 1.3694 - val_acc: 0.6079\n",
    "Epoch 23/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0728 - acc: 0.6630 - val_loss: 1.3627 - val_acc: 0.6066\n",
    "Epoch 24/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0642 - acc: 0.6651 - val_loss: 1.3673 - val_acc: 0.6077\n",
    "Epoch 25/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0560 - acc: 0.6671 - val_loss: 1.3684 - val_acc: 0.6068\n",
    "Epoch 26/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0461 - acc: 0.6702 - val_loss: 1.3782 - val_acc: 0.6065\n",
    "Epoch 27/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0385 - acc: 0.6720 - val_loss: 1.3897 - val_acc: 0.6054\n",
    "Epoch 28/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0295 - acc: 0.6749 - val_loss: 1.3945 - val_acc: 0.6053\n",
    "Epoch 29/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.0213 - acc: 0.6774 - val_loss: 1.4086 - val_acc: 0.6054\n",
    "Epoch 30/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.0134 - acc: 0.6792 - val_loss: 1.4139 - val_acc: 0.6052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "'''\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "json_string = model1.to_json()\n",
    "open(path + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model1.save_weights(path + 'models/w_' + model_name + '.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "model1 = model_from_json(open(path + 'models/mdl_' + model_name + '.json').read())\n",
    "model1.load_weights(path + 'models/w_' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "\n",
    "def sample(a, diversity=1.0):\n",
    "    '''\n",
    "    helper function to sample an index from a probability array\n",
    "    - Diversity control the level of randomless\n",
    "    '''\n",
    "    a = np.log(a) / diversity\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def generate_text(sentence, diversity, current_model, num_char=400):\n",
    "    sentence_init = sentence\n",
    "    generated = ''\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        preds = current_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print('\\n\\nDIVERSITY: ',diversity,'\\n')\n",
    "    print(sentence_init + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "mire vuestra merced de parecer que el mundo se ha de aqu√≠ a su ama, y el cura se le pasaba de la manera, que no se le pareci√≥ que est√° en el mundo de la vida, que es la mayor y me pareci√≥ que estaba de mi casa, y el que est√° en el mundo y a la se√±ora dulcinea del toboso y el caballero de la triste figura, y el caballero de la triste figura, que era la venta la duquesa de la caballer√≠a, que es lo que se le dije\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "mire vuestra merced parece, pues, la cual es mejor que se entre las manos y de cabeza de parecer al principio en el cuerpo, y con esto le dijo:\n",
      "\n",
      "-se√±or don quijote, y el cura y el mal tal de la mancha, por la cual se le dijese que su amo de m√°s se lo hayan.\n",
      "\n",
      "-por esto se puede ser de los de las mismas cosas m√°s a su ama. si estaba diciendo que estaba de tanto camino para ser una grande amiga de la andante caba\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "mire vuestra merced luego, que de aquel alitado rico cu√°ndo\n",
      "visto, y vino en su caballo.\n",
      "\n",
      "-en todo eso, vienes sumos los ancallar y bemas como ver la misma manera que a un fung√≠simo consejo\n",
      "cuando ninguno nodulan.bidor los hilos que los acometemos, o para mejor que me ha de aqu√≠ la tendida lotoria, y as√≠,\n",
      "no vuestra merced ha dicho y todos caballeros andantes; la tres principales\n",
      "metidos; que, estando piens\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "mire vuestra merced -dijo el autor hab√≠a mucho grande rodel de las armas; y, menos la nombre como si le quiso modo\n",
      "ni hasta que, para mostrar lo que ordenaba prosigui√≥ sancho; porque de sobre la gigante g√©nera el fue\n",
      "con su pecho.\n",
      "\n",
      "esto m√°s le responda de tigas; y vimos su amentura; la cual, hab√≠an sido pasamientos, que ya tengo o\n",
      "d√©ndolo.\n",
      "\n",
      "-sea mandado, hacer el revertado dello,    oyemon tus vuestras\n",
      "\n",
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "de lo que sucedi√≥ a la venta, en la cual se le dijese la ventera de la mancha, y la poca perdici√≥n que se le pareci√≥ que est√° en el camino para ser de la mancha, y la comedia se le perdieron a su se√±ora, que es el mundo que est√° en la mano, y con las manos de la mancha, por estar a mi casa, se le pareci√≥ que all√≠ no se le hab√≠a de haber\n",
      "contento a la vista y de la mano de la caballer√≠a, y as√≠ lo hab√≠a de\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "de lo que sucedi√≥ a la venta, y con la tierra su parte en la mano, y as√≠, comenz√≥ a sancho que el cura quedaba de la alta manda, y que los m√≠os de la triste figura le hac√≠a, que es el mundo que hay en el mundo que puro y tengo visto, porque el\n",
      "mono en la cabeza de la alta princesa del caso, y el contrario se pusieron en la aldea de caballer√≠as, que all√≠ los mayores y milagros en este pensamiento por de sus ar\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "de lo que sucedi√≥ a una\n",
      "   la virtud verdad que\n",
      "sota tan salida a entendido, de\n",
      "su tiempo sancho a esto el duque y el √°nimo\n",
      "se lo pudiere decir a mis poderas, natural de\n",
      "valenconcella, mila, conven√≠a que puede ser marqu√©s por sus humanos armistemente y como por dios en tu costa dic√≠simo poeta, porque se mate de su\n",
      "linaje por el pensamiento, pues yo say√© toda tales pensao\n",
      "que no era menester\n",
      "para el cura\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "de lo que sucedi√≥ a buerandamente dorotea, y que m√°s muerto, arrojo. digo, traistes vistos y no ser√°s sonetos,\n",
      "sois escuderos que me\n",
      "cabal√≥ el cuerpo se olvigan, de mandar como el soldado, y\n",
      "vasaun secleo, cinto la causa que\n",
      "nos ha oyendo en aquella gana y historia de viento, pues sombra hubo le trojado de noimeria, y a la\n",
      "menosbaraban de dios que andaba del salido envialmento, en\n",
      "la lilma teas y la fabola \n",
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "de all√≠ a poco comenzaron a dicio que la de las manos de la mancha, que es la de las manos de la mancha, all√≠ hablada y de las mejores y miserables manos de la mancha, el cual, por la mesa de las letras, y que el se√±or mandaros a los que la de la mancha que la de las manos de su escudero, y que el que le pareci√≥ que est√° en el camino para despertar de los pensamientos y de la cabeza y para que se le hab√≠a de ha\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "de all√≠ a poco comenzaron a probar el apusti√≥ la cabeza y con el\n",
      "mundo. y as√≠, le dijo:\n",
      "\n",
      "-eso no har√© todo esto dej√≥ la mitad del camino admirado que se le dejase de mi vida -replic√≥ don quijote-; y, con todo eso, y caballero llamado como el acompa√±amiento, que de tu pregunta se le pasase de la mula y el torte para del mundo y se dos faltan a todos los que llaman palabras de sus intenciones de todos los que\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "de all√≠ a poco comenz√≥ conmigo; y a lo menes, ser√° en sola suya que esto es pelo, fea de no est√°ramos as√≠:\n",
      "\n",
      "hici√©ramele, de alta por ocustra caballer√≠a; y as√≠, lle√©tese,\n",
      "con alz√≥n todo.\n",
      "\n",
      "-no deslar√≠amos el ercote, como si atribo de sus intentos para les provecho, nos\n",
      "hubieran hallado su honestidad como si\n",
      "llevaste -dijo don quijote-. sancho hijo, amigo, que lo ser√° en las casas y mandaron los\n",
      "hida\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "de all√≠ a poco comenzaron a sustentor y ofrecimiento al mabelaso el gente que para d√≠n. entre √©l entierra muchas muchos atisma, que no la\n",
      "dejar√≠a matro, me ser√° que dol√©is en la casa\n",
      "de miente por remedio al de\n",
      "los pedradares, y no vista ladr√≥n de vino en lo necesidad de cera\n",
      "pil brencia con la humidad de unos balcospes de alguna\n",
      "alcorjapa. ahora ya estoy, con con buenes nocheber, ni\n",
      "menomos m√°s primero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = 'mire vuestra merced '\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de lo que sucedi√≥ a'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de all√≠ a poco come'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

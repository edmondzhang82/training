{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a RNN model to text generation\n",
    "- RNN model at character level\n",
    "    - Input: n character previous\n",
    "    - Output: next character\n",
    "    - Model LSTM\n",
    "- Use 'El Quijote' to train the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = '/home/ubuntu/data/training/keras/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and generate sequences\n",
    "\n",
    "Download quijote from guttenberg project\n",
    "\n",
    "\n",
    "wget http://www.gutenberg.org/cache/epub/2000/pg2000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2198927\n",
      "Chars list:  ['\\n', '\\r', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x81', '\\x89', '\\x8d', '\\x91', '\\x93', '\\x9a', '\\xa0', '\\xa1', '\\xa9', '\\xab', '\\xad', '\\xaf', '\\xb1', '\\xb3', '\\xb9', '\\xba', '\\xbb', '\\xbc', '\\xbf', '\\xc2', '\\xc3', '\\xef']\n",
      "total chars: 80\n"
     ]
    }
   ],
   "source": [
    "#Read book\n",
    "text = open(path + \"pg2000.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('Chars list: ', chars)\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "#Dictionaries to convert char to num & num to char\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 732869\n",
      "e nombre el r√≠o taj - o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "# One sentence of length 20 for each 3 characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(300, len(text) - maxlen, step): #Start in line 30 to exclude Gutenberg header.\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "print(sentences[4996], '-', next_chars[4996])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "X shape:  (732869, 20, 80)\n",
      "y shape:  (732869, 80)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X: One row by sentence\n",
    "    in each row a matrix of bool 0/1 of dim length_sentence x num_chars coding the sentence. Dummy variables\n",
    "y: One row by sentence\n",
    "    in each row a vector of bool of lengt num_chars with 1 in the next char position\n",
    "'''\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print('X shape: ',X.shape)\n",
    "print('y shape: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "prev (InputLayer)                (None, 20, 80)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 20, 512)       1214464     prev[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 512)           2099200     lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 80)            41040       lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 3354704\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "print('Build model 1')\n",
    "seq_prev_input = Input(shape=(maxlen, len(chars)), name='prev') \n",
    "                \n",
    "# apply forwards LSTM\n",
    "forwards1 = LSTM(512, dropout_W=0.3, dropout_U=0.3, return_sequences=True)(seq_prev_input)\n",
    "\n",
    "forwards2 = LSTM(512, dropout_W=0.3, dropout_U=0.3, return_sequences=False)(forwards1)\n",
    "\n",
    "output = Dense(len(chars), activation='softmax')(forwards2)\n",
    "\n",
    "model1 = Model(input=seq_prev_input, output=output)\n",
    "model1.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"268pt\" viewBox=\"0.00 0.00 120.00 268.00\" width=\"120pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 264)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-264 116,-264 116,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140666222649488 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140666222649488</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-223 -0.5,-259 112.5,-259 112.5,-223 -0.5,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-237.3\">prev (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140665749659536 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140665749659536</title>\n",
       "<polygon fill=\"none\" points=\"4,-149 4,-185 108,-185 108,-149 4,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-163.3\">lstm_1 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140666222649488&#45;&gt;140665749659536 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140666222649488-&gt;140665749659536</title>\n",
       "<path d=\"M56,-222.937C56,-214.807 56,-204.876 56,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-195.441 56,-185.441 52.5001,-195.441 59.5001,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140666223116688 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140666223116688</title>\n",
       "<polygon fill=\"none\" points=\"4,-75 4,-111 108,-111 108,-75 4,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-89.3\">lstm_2 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140665749659536&#45;&gt;140666223116688 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140665749659536-&gt;140666223116688</title>\n",
       "<path d=\"M56,-148.937C56,-140.807 56,-130.876 56,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-121.441 56,-111.441 52.5001,-121.441 59.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140664130012112 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140664130012112</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-1 2.5,-37 109.5,-37 109.5,-1 2.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56\" y=\"-15.3\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140666223116688&#45;&gt;140664130012112 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140666223116688-&gt;140664130012112</title>\n",
       "<path d=\"M56,-74.937C56,-66.8072 56,-56.8761 56,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.5001,-47.4406 56,-37.4407 52.5001,-47.4407 59.5001,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the model\n",
    "#Plot the model graph\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model1).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600000 samples, validate on 132869 samples\n",
      "Epoch 1/30\n",
      "600000/600000 [==============================] - 625s - loss: 2.3064 - acc: 0.3143 - val_loss: 1.9490 - val_acc: 0.4013\n",
      "Epoch 2/30\n",
      "600000/600000 [==============================] - 694s - loss: 1.8458 - acc: 0.4247 - val_loss: 1.7759 - val_acc: 0.4594\n",
      "Epoch 3/30\n",
      "600000/600000 [==============================] - 694s - loss: 1.5572 - acc: 0.5090 - val_loss: 1.5789 - val_acc: 0.5218\n",
      "Epoch 6/30\n",
      " 18432/600000 [..............................] - ETA: 626s - loss: 1.5344 - acc: 0.5137"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c032a011fb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model1.fit(X[:600000], y[:600000], batch_size=512, nb_epoch=30,\n\u001b[0;32m----> 3\u001b[0;31m            validation_data=(X[600000:], y[600000:]))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "history = model1.fit(X[:600000], y[:600000], batch_size=512, nb_epoch=30,\n",
    "           validation_data=(X[600000:], y[600000:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train on 600000 samples, validate on 132869 samples\n",
    "Epoch 1/30\n",
    "600000/600000 [==============================] - 523s - loss: 2.2971 - acc: 0.3154 - val_loss: 1.9305 - val_acc: 0.4111\n",
    "Epoch 2/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.8107 - acc: 0.4357 - val_loss: 1.7215 - val_acc: 0.4805\n",
    "Epoch 3/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.6351 - acc: 0.4875 - val_loss: 1.6226 - val_acc: 0.5123\n",
    "Epoch 4/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.5340 - acc: 0.5168 - val_loss: 1.5604 - val_acc: 0.5306\n",
    "Epoch 5/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.4689 - acc: 0.5361 - val_loss: 1.5244 - val_acc: 0.5443\n",
    "Epoch 6/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.4232 - acc: 0.5494 - val_loss: 1.5053 - val_acc: 0.5508\n",
    "Epoch 7/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.3890 - acc: 0.5596 - val_loss: 1.4823 - val_acc: 0.5579\n",
    "Epoch 8/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.3618 - acc: 0.5672 - val_loss: 1.4643 - val_acc: 0.5625\n",
    "Epoch 9/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.3409 - acc: 0.5730 - val_loss: 1.4587 - val_acc: 0.5667\n",
    "Epoch 10/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.3231 - acc: 0.5784 - val_loss: 1.4466 - val_acc: 0.5690\n",
    "Epoch 11/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.3084 - acc: 0.5819 - val_loss: 1.4398 - val_acc: 0.5736\n",
    "Epoch 12/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2954 - acc: 0.5864 - val_loss: 1.4360 - val_acc: 0.5740\n",
    "Epoch 13/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2839 - acc: 0.5885 - val_loss: 1.4296 - val_acc: 0.5776\n",
    "Epoch 14/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2751 - acc: 0.5913 - val_loss: 1.4275 - val_acc: 0.5785\n",
    "Epoch 15/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2645 - acc: 0.5944 - val_loss: 1.4230 - val_acc: 0.5794\n",
    "Epoch 16/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2578 - acc: 0.5963 - val_loss: 1.4182 - val_acc: 0.5816\n",
    "Epoch 17/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2508 - acc: 0.5988 - val_loss: 1.4202 - val_acc: 0.5818\n",
    "Epoch 18/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2455 - acc: 0.6005 - val_loss: 1.4151 - val_acc: 0.5812\n",
    "Epoch 19/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2394 - acc: 0.6017 - val_loss: 1.4133 - val_acc: 0.5836\n",
    "Epoch 20/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2332 - acc: 0.6037 - val_loss: 1.4099 - val_acc: 0.5848\n",
    "Epoch 21/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.2288 - acc: 0.6051 - val_loss: 1.4164 - val_acc: 0.5837\n",
    "Epoch 22/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2247 - acc: 0.6057 - val_loss: 1.4102 - val_acc: 0.5861\n",
    "Epoch 23/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.2215 - acc: 0.6067 - val_loss: 1.4080 - val_acc: 0.5873\n",
    "Epoch 24/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2167 - acc: 0.6078 - val_loss: 1.4099 - val_acc: 0.5855\n",
    "Epoch 25/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2124 - acc: 0.6097 - val_loss: 1.4050 - val_acc: 0.5876\n",
    "Epoch 26/30\n",
    "600000/600000 [==============================] - 522s - loss: 1.2111 - acc: 0.6101 - val_loss: 1.4105 - val_acc: 0.5868\n",
    "Epoch 27/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2059 - acc: 0.6116 - val_loss: 1.4027 - val_acc: 0.5879\n",
    "Epoch 28/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.2026 - acc: 0.6122 - val_loss: 1.4048 - val_acc: 0.5868\n",
    "Epoch 29/30\n",
    "600000/600000 [==============================] - 523s - loss: 1.1990 - acc: 0.6138 - val_loss: 1.4090 - val_acc: 0.5887\n",
    "Epoch 30/30\n",
    "600000/600000 [==============================] - 524s - loss: 1.1969 - acc: 0.6139 - val_loss: 1.4053 - val_acc: 0.5889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-422066002d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "'''\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "json_string = model1.to_json()\n",
    "open(path + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model1.save_weights(path + 'models/w_' + model_name + '.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "model1 = model_from_json(open(path + 'models/mdl_' + model_name + '.json').read())\n",
    "model1.load_weights(path + 'models/w_' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "\n",
    "\n",
    "def sample(a, diversity=1.0):\n",
    "    '''\n",
    "    helper function to sample an index from a probability array\n",
    "    - Diversity control the level of randomless\n",
    "    '''\n",
    "    a = np.log(a) / diversity\n",
    "    a = np.exp(a) / np.sum(np.exp(a), axis=0)\n",
    "    a /= np.sum(a+0.0000001) #Precission error\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def generate_text(sentence, diversity, current_model, num_char=400):\n",
    "    sentence_init = sentence\n",
    "    generated = ''\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        preds = current_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print()\n",
    "    print('DIVERSITY: ',diversity)\n",
    "    print(sentence_init + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIVERSITY:  0.2\n",
      "mire vuestra merced que est√° en la memoria de la mano de la mano de la mano, y a lo menos que en la cabeza de la mano, sino que despu√©s de haber de haber de contar la vida de la mano de la mano de mi se√±ora dulcinea del toboso, y el cura que el m√°s deseo que le hab√≠a de ser el mundo de la cabeza de la cabeza, y aun en la misma mano y de los dem√°s de la mano de los ojos de los caballeros andantes que en la mitad\n",
      "\n",
      "DIVERSITY:  0.5\n",
      "mire vuestra merced dicen que se le pareci√≥ que un poco se le parec√≠a, que no pod√≠a ser cosa de los encubiertos y despedirme del mundo, y que est√° agravio de los presentes, y de los molineros del toboso, a la se√±ora dulcinea del toboso, sino que no es muy bueno. andando esto,\n",
      "volviendo a don quijote y sancho en la mano, y de aqu√©lla que all√≠ juntase.\n",
      "\n",
      "-no es eso -respondi√≥ el cura-: ¬øpor el mesmo se estim\n",
      "\n",
      "DIVERSITY:  1\n",
      "mire vuestra merced se√±or don bernado, y, con otro don quijote sancho, se le hab√≠a parec√≠a buen segundo, y volver√© con alguna parte.\n",
      "\n",
      "no debe de ser grande apearse otra\n",
      "cosa que de los dem√°s debidos m√≥sicos gaulanos, y luego la duquesa, pero no hall√© sobre los cuadrilleros antes que tiene por los hombros del duque y con estar entonces como un letre muley que era menester: s√≥lo quiero que sea frefentando la\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "mire vuestra merced aqu√≠ es otra\n",
      " anochecina.\n",
      "\n",
      "-pues, dogna se√±or, dar, no\n",
      "pudo todas las cruzan, ya se me arraja, cuando\n",
      "m√°s, que sancho quedaramos; que a aquel primero sobre aquellos honres con odejas, y pregunt√°ronlos los caballeros?\n",
      "\n",
      "y, dec√≠a que es trato, diciendo:\n",
      "\n",
      "cuardo esto me cost√°bemos;\n",
      "   ya leta o enojo a un caballo un lacagio prometido, a\n",
      "luscinda, y √©l fue como sus manos qui√©n dillam\n",
      "\n",
      "DIVERSITY:  0.2\n",
      "de lo que sucedi√≥ a la mano de la mano de los dem√°s de los ojos de la mesma cosa, y el deseo de la mano de la mano de la mano de la mano de la mano de la cabeza, y en la mesma historia de la mano de la mano de la mano, y que estaba en la mitad de la mano y de los dem√°s de los ojos de los dem√°s de los dem√°s de la mujer de la mano de los caballeros andantes que el modo que en la mitad del caballero de la mano, y l\n",
      "\n",
      "DIVERSITY:  0.5\n",
      "de lo que sucedi√≥ a don fernando, dijo:\n",
      "\n",
      "-no es la mejor que hacer otra cosas de manera que no se hallar√°\n",
      "en el mundo que con mucha presteza y los brazos a la cabeza de las manos, que no este mal\n",
      "nombre de mi padre, en la gran cual no pod√≠a\n",
      "dejar de mandar y a los entretenidos, y despu√©s de haber puesto en la cabeza en la cabeza, como yo tengo de ser costumbre de mi raz√≥n, y de la m√°s nueva de la cabeza, p\n",
      "\n",
      "DIVERSITY:  1\n",
      "de lo que sucedi√≥ aunque hab√≠a curado del\n",
      "molidor. este don quijote -respondi√≥ sancho-, para\n",
      "media√±a que he dicho, que suele ser hermosura que confuso sois yo que lo dijo que en aquel mal se pidieron decir que\n",
      "huyen suplico\n",
      "dorotea del que aquel mal\n",
      "tierra; y as√≠, dejaba de ser lugares de su grande espada, pues no es esto, se lleg√≥ a albarda, aunque dijo la doncella\n",
      "que no pod√≠a menester cosa mucha\n",
      "vece\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "de lo que sucedi√≥ a cumplir los antiguos contornos con\n",
      "sus indiciones que esitan fueron, la su profesi√≥n! iba sancho a un p√©raro, de preguntas comodiantes, y camino a movimiento,\n",
      "diciendo:\n",
      "\n",
      "-doradme, cuando he contado entre encantador o√≠lo d√©jemos\n",
      "m√≠simo valdo, dedota el viaje como ellos\n",
      "pod√≠an pesadumbre en poco un d√≠as o leyendado un tal s√≠lo por este grito? ¬øqui√©n\n",
      "vio que afecha estaban; y, puest\n",
      "\n",
      "DIVERSITY:  0.2\n",
      "de all√≠ a poco comenz√≥ a su deseo de su caballero andante, que no la hab√≠a de ser con los deseos de la mano, y los dem√°s de los dem√°s de los dem√°s de la cabeza, y que en la mitad del cabrero, y al modo de los dem√°s de la mano de los dem√°s de la mano de los cuatro del mundo.\n",
      "\n",
      "-¬øqu√© es lo que dicen que estaban en la mano de la mano de la mano de la cabeza, y los dos le dijo:\n",
      "\n",
      "-¬øqu√© mal se ha de all√≠ a \n",
      "\n",
      "DIVERSITY:  0.5\n",
      "de all√≠ a poco comenz√≥ a su casa, y aun a la mujer de la mano de la deseo de la duquesa y por los dem√°s de la cabeza, y no le pareci√≥ que hab√≠a de ser el nombre de la belleza de los de la mano, vio el cura que el que le hab√≠a de tener la cabeza y desenga√±ado me diga.\n",
      "\n",
      "-yo le digo dorotea -respondi√≥ sancho-, que estaba con la mitad de las\n",
      "rodrigas de los cuatro d√≠as que me despedir√≠an en la memoria del ca\n",
      "\n",
      "DIVERSITY:  1\n",
      "de all√≠ a poco comer, con todo\n",
      "lo que vuestra merced le ayude ni hubiera\n",
      "hecho. conocimiento que cuando en\n",
      "este punto o salir a las se√±oras y l√≠melas de dos seis\n",
      "prendistes no pensaban en el pulto\n",
      "del honesto, con un aire -dijo el cura-, la que tengo discreta en\n",
      "que no se le aguardaba, aunque d√© a los diestros a\n",
      "lo que tenmo, y en el aire y se√±ores, y ser√° decir que en una de las entra√±as ang√≥latas a l\n",
      "\n",
      "DIVERSITY:  1.2\n",
      "de all√≠ a poco comenz√≥ a entender que yo le vea un bien alguno hay nadie en salir a vuestra incomodida.\n",
      "\n",
      "a esto que oo granj√© como por su\n",
      "muchujeres y niego en un sentido, h√≥ralme hubieran de arcabucendo; el valeroso dejando, de ver m√°s be√±ita y de los √°rboles como la\n",
      "leyesen, a ten√≠a casa para sobresatino y le deb√≠a\n",
      "venir que aun no era la m√°s se√±ora ac√≥momo, cual, as√≠ como es elandro.\n",
      "\n",
      "-tropizco\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = 'mire vuestra merced '\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de lo que sucedi√≥ a'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de all√≠ a poco come'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "mire vuestra merced dec√≠s, y que se le pareci√≥ que en la cabeza de la cabeza, y el caballero del caballero de la cabeza, y los dem√°s de los dem√°s de los dem√°s de los dem√°s de la mano de la mujer de la mano de la mano, y aun a su se√±ora dulcinea del toboso, y el cura que el caballero de la mano que le pareci√≥ que estaba en la misma cosa que en la mitad del caballero de la mano, se le dijo:\n",
    "\n",
    "-no s√© -respondi\n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "mire vuestra merced que no est√° en la cabeza. pero, en efeto, pues todo aquello que est√° en el mundo que cada uno deb√≠a\n",
    "de ser con la misma sierra parte de la muerte de la mano, con todo el mundo me la conoci√≥, que ten√≠a por el primero que est√°n el rostro en las manos, y al se√±or don quijote -respondi√≥ sancho-, porque en la puerta de los sucesos del buen estado de la desencantada de los ojos.\n",
    "\n",
    "-¬øqu√© mal \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "mire vuestra merced que, aunque, desdicho y tiempo viene, a\n",
    "cuya cabeza destos tres, los informaciones que dejara de serle, que me fueron? ¬øadmirado,\n",
    "\n",
    "y, creyendo que me va y enfermo. y esto que tienen entonces las requiebros que algunos limpios en un ampeoso como si improvisentes en sus insimulables y en los m√≠os al que el honesto, en la mano de mucho premio y don quijote fingi√≥no los dos o sabidores, y,\n",
    "acom\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "mire vuestra merced paso que no sa cluero-. subi√≥, se√±or,\n",
    "le hubiera vuelto el duque, que pica, yo fue poseÔøΩr√≠a de guardar cierto. para los dem√°s, esperando la misma tragua debe de haberlas hallado su santa hijo ni deb√≠an para m√≠, porque yo hay de platar pre subir t√∫ turba -dijo el deleitable-; otras porturas, sino como alabanzas y\n",
    "comedimientos puciese\n",
    "los d√≠as de lo que von mirado despu√©s de\n",
    "visi√≥n de\n",
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "de lo que sucedi√≥ a la mano de la mano de la mano de los ojos de la mano de la mano de la mano, y aun m√°s que se le dijese la mano de la mano y en la mitad del caballero del caballero de la mano de la mano, y que el parte de la mano, y que en la mitad del caballero de la mano, sino a la puerta de la mano de la mano de la mano de los dem√°s de la cabeza, y el cura y la cabeza de la mano y en la cabeza de la cabeza, \n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "de lo que sucedi√≥ a camila, por ser tan alta de la mano y en voz brazo? ¬øqu√© es lo que pudiera, se√±or don quijote que en las fermosuras que despu√©s que le sacar√°n con don quijote hab√≠a de ser la duquesa, la cual no le hab√≠a de ser muy buena como gausa, y si este deseo de ser mejor que en la cabeza est√° a los dos de la mano, y su amo no le puede dar a su casa por los manos de mano, diciendo:\n",
    "\n",
    "-pues, ¬øqu√© \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "de lo que sucedi√≥ a las m√°s faltas cuentan haciendo:\n",
    "\n",
    "-ÔøΩqcorr√≠an por esto, bueno -respondi√≥ c√≥mo est√° aquel mano tra√≠a furia por ella estajo\n",
    "m√°s que andaba y fingi√≥n de sus apartieron de modo que no\n",
    "hay vasto qu√© hizo con gald√°is que soy sin duda, duque ni en la m√°s\n",
    "buena gran se√±ora dulcinea; y as√≠ lo han don quijote y no bastaba junto a nuestra\n",
    "se√±ora dulcinea, ahora\n",
    "la entienda, el aposento a\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "de lo que sucedi√≥ al\n",
    "admiraci√≥n, dijo:\n",
    "\n",
    "-eso me esplevo en raz√≥n encantada, y su venimo tiempo, que pasaba tan hirtoria. es\n",
    "\n",
    "don quijote, le dijo:\n",
    "\n",
    "y cuando jam√°s:\n",
    "  si ya entienden en mi padre desde aqu√≠ vean fuerza, como yo\n",
    "costa yo he o√≠do decir, el rey\n",
    "\n",
    "venci√≥n que √©sto, que lo m√©s comenz√≥ a vuestra merced colgar√© por la orden y parece que\n",
    "pudieron semplarse. el cual, si de la mono.\n",
    "acudiÔøΩ\n",
    "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
    "de all√≠ a poco comenz√≥ a su caballero andante, que en la m√°s hermosa de la mano, y el cura que el mundo ten√≠a con el cura y el de la mano de la cabeza de la mano de la mano de la mano de la mano de la cabeza, y a los dem√°s de los cuatro de la mano de la mano de la mano y en la mitad del caballero de la cabeza, y le dijo:\n",
    "\n",
    "-¬°oh sancho -dijo el cura-, que no se le hab√≠an de ser manos de los dem√°s de los de la\n",
    "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
    "de all√≠ a poco comenz√≥ a la vida de la mano de\n",
    "arriba al mundo. pero, con todo eso, ha de ser el rostro de las linajes de su escudero. por el rey en el mundo de la industria que en su caballero andante; y, aunque se volvi√≥ a camila y de la mano de la muerte de mi cabeza? y as√≠, como el tal caballero andante, que los dem√°s juramentos, y con la mitad del toboso, y as√≠, por decir que os son de all√≠ a los deseos \n",
    "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
    "de all√≠ a poco comenz√≥\n",
    "a dos crazos de entender que tratar la nueva al desde nuevas andantes de solos con los detros donde me hubieran\n",
    "de subir la sumiera y rabia la duquesa\n",
    "   a un hacer con un gato, que le\n",
    "dijo juntar la locura para su\n",
    "amo, para que quisieron decir alguna, vino\n",
    "todas aquellos dem√°s caballeros. pero, sancho, tanto, viendo camila la primero tiene: prodici√≥n\n",
    "que yo le dio caminar las belloz\n",
    "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
    "de all√≠ a poco comer. otros d√≠as se le pid√≠a hablar de cerra\n",
    "   que el gate predice\n",
    "y otras puntas del cordel bestia.\n",
    "\n",
    "-yo no por eso, decar√≠a sobre la venta, porque √©l saslos dem√°s sin √©l que\n",
    "llevase a buscar de la suma, sancho mil√°tico, cuando pos√≠an los zogados. y si as√≠, mi rendido a\n",
    "cuerpo, ni en llopar sali√≥ el baece-, que el h√°b√≠simo que viene por\n",
    "los tratas y tontos que sean, y el de los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

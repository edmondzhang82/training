{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a RNN model to text generation\n",
    "- RNN model at character level\n",
    "    - Input: n character previous\n",
    "    - Output: next character\n",
    "    - Model LSTM\n",
    "- Use 'El Quijote' to train the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "#path_base = '/Users/jorge/'\n",
    "path_base = '/home/jorge/'\n",
    "\n",
    "path = path_base + 'data/training/keras/'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Download quijote from guttenberg project\n",
    "# wget http://www.gutenberg.org/ebooks/2000.txt.utf-8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 2198927)\n",
      "('total chars:', 80)\n",
      "e por su nobleza no se abaten al servicio y granjerías del\r\n",
      "vulgo, he determinado de sacar a luz al ingenioso hidalgo don quijote de la\r\n",
      "mancha, al a\n"
     ]
    }
   ],
   "source": [
    "text = open(path + \"2000.txt.utf-8\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "#Dictionaries to convert char to num & num to char\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print text[5540:5690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\x81', 1: '@', 2: '\\x89', 3: '\\xad', 4: '\\xba', 5: '\\n', 6: '\\r', 7: '\\x91', 8: '\\x93', 9: '\\xef', 10: '\\x9a', 11: '/', 12: '\\xa1', 13: ' ', 14: '#', 15: ')', 16: '%', 17: '$', 18: \"'\", 19: '\\xa9', 20: '(', 21: '\\xab', 22: '*', 23: '-', 24: ',', 25: '\\xaf', 26: '.', 27: '1', 28: '0', 29: '\\xb3', 30: '2', 31: '5', 32: '4', 33: '7', 34: '6', 35: '9', 36: '8', 37: '\\xbb', 38: ':', 39: '\\xbc', 40: '\\xbf', 41: '?', 42: '!', 43: '\\xc3', 44: '\\xc2', 45: '\\xa0', 46: '\\x8d', 47: '3', 48: '\\xb9', 49: '\"', 50: '[', 51: ']', 52: ';', 53: '\\xb1', 54: 'a', 55: 'c', 56: 'b', 57: 'e', 58: 'd', 59: 'g', 60: 'f', 61: 'i', 62: 'h', 63: 'k', 64: 'j', 65: 'm', 66: 'l', 67: 'o', 68: 'n', 69: 'q', 70: 'p', 71: 's', 72: 'r', 73: 'u', 74: 't', 75: 'w', 76: 'v', 77: 'y', 78: 'x', 79: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print indices_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 732869)\n",
      "e nombre el río taj - o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "# One sentence of length 20 for each 3 characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(300, len(text) - maxlen, step): #Start in line 30 to exclude Gutenberg header.\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "print sentences[4996], '-', next_chars[4996]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "('X shape: ', (732959, 20, 80))\n",
      "('y shape: ', (732959, 80))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X: One row by sentence\n",
    "    in each row a matrix of bool 0/1 of dim length_sentence x num_chars coding the sentence. Dummy variables\n",
    "y: One row by sentence\n",
    "    in each row a vector of bool of lengt num_chars with 1 in the next char position\n",
    "'''\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print('X shape: ',X.shape)\n",
    "print('y shape: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ...,  True False False]\n",
      " [False False False ..., False False False]]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "('X shape: ', (732869, 20, 80))\n",
      "('y shape: ', (732869,))\n"
     ]
    }
   ],
   "source": [
    "#Export sequiences to hdf5 to model in torch\n",
    "\n",
    "print('Vectorization...')\n",
    "X_num = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.uint8)\n",
    "y_num = np.zeros(len(sentences), dtype=np.uint8)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_num[i, t, char_indices[char]] = 1\n",
    "    y_num[i] = char_indices[next_chars[i]]\n",
    "\n",
    "print('X shape: ',X_num.shape)\n",
    "print('y shape: ',y_num.shape)    \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] 57\n"
     ]
    }
   ],
   "source": [
    "print X_num[2], y_num[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save depurated characters to hdf5\n",
    "import h5py\n",
    "\n",
    "hdf5_f = h5py.File(path + \"sequences20_quijote.hdf5\",mode='a')\n",
    "\n",
    "if \"X\" in hdf5_f:\n",
    "    del hdf5_f[\"X\"]\n",
    "hdf5_f.create_dataset(\"X\", data = X_num) \n",
    "\n",
    "if \"y\" in hdf5_f:\n",
    "    del hdf5_f[\"y\"]\n",
    "hdf5_f.create_dataset(\"y\", data = y_num)\n",
    "\n",
    "hdf5_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "print('Build model 1')\n",
    "seq_prev_input = Input(shape=(maxlen, len(chars)), name='prev') \n",
    "                \n",
    "# apply forwards LSTM\n",
    "forwards1 = LSTM(512, return_sequences=True)(seq_prev_input)\n",
    "dp1 = Dropout(0.25)(forwards1)\n",
    "\n",
    "forwards2 = LSTM(512, return_sequences=False)(dp1)\n",
    "dp2 = Dropout(0.5)(forwards2)\n",
    "\n",
    "output = Dense(len(chars), activation='softmax')(dp2)\n",
    "\n",
    "model1 = Model(input=seq_prev_input, output=output)\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Print the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit model\n",
    "history = model1.fit(X[:600000], y[:600000], batch_size=256, nb_epoch=30,\n",
    "           validation_data=(X[600000:], y[600000:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build model 1\n",
    "Train on 600000 samples, validate on 182592 samples\n",
    "Epoch 1/30\n",
    "600000/600000 [==============================] - 487s - loss: 1.9885 - acc: 0.4203 - val_loss: 1.6397 - val_acc: 0.5098\n",
    "Epoch 2/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.5699 - acc: 0.5284 - val_loss: 1.4750 - val_acc: 0.5557\n",
    "Epoch 3/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.4520 - acc: 0.5609 - val_loss: 1.4135 - val_acc: 0.5743\n",
    "Epoch 4/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3890 - acc: 0.5785 - val_loss: 1.3771 - val_acc: 0.5831\n",
    "Epoch 5/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3439 - acc: 0.5908 - val_loss: 1.3532 - val_acc: 0.5908\n",
    "Epoch 6/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.3109 - acc: 0.5994 - val_loss: 1.3413 - val_acc: 0.5933\n",
    "Epoch 7/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2844 - acc: 0.6066 - val_loss: 1.3297 - val_acc: 0.5976\n",
    "Epoch 8/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2618 - acc: 0.6122 - val_loss: 1.3234 - val_acc: 0.6006\n",
    "Epoch 9/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2418 - acc: 0.6176 - val_loss: 1.3203 - val_acc: 0.6026\n",
    "Epoch 10/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.2245 - acc: 0.6222 - val_loss: 1.3204 - val_acc: 0.6052\n",
    "Epoch 11/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.2076 - acc: 0.6267 - val_loss: 1.3223 - val_acc: 0.6057\n",
    "Epoch 12/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1936 - acc: 0.6308 - val_loss: 1.3190 - val_acc: 0.6068\n",
    "Epoch 13/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1795 - acc: 0.6348 - val_loss: 1.3223 - val_acc: 0.6066\n",
    "Epoch 14/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1672 - acc: 0.6379 - val_loss: 1.3317 - val_acc: 0.6071\n",
    "Epoch 15/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1563 - acc: 0.6410 - val_loss: 1.3220 - val_acc: 0.6063\n",
    "Epoch 16/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1443 - acc: 0.6439 - val_loss: 1.3279 - val_acc: 0.6070\n",
    "Epoch 17/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1314 - acc: 0.6467 - val_loss: 1.3320 - val_acc: 0.6080\n",
    "Epoch 18/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1236 - acc: 0.6494 - val_loss: 1.3453 - val_acc: 0.6085\n",
    "Epoch 19/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1108 - acc: 0.6533 - val_loss: 1.3426 - val_acc: 0.6088\n",
    "Epoch 20/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.1030 - acc: 0.6551 - val_loss: 1.3536 - val_acc: 0.6090\n",
    "Epoch 21/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0923 - acc: 0.6573 - val_loss: 1.3491 - val_acc: 0.6071\n",
    "Epoch 22/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0814 - acc: 0.6599 - val_loss: 1.3694 - val_acc: 0.6079\n",
    "Epoch 23/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0728 - acc: 0.6630 - val_loss: 1.3627 - val_acc: 0.6066\n",
    "Epoch 24/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0642 - acc: 0.6651 - val_loss: 1.3673 - val_acc: 0.6077\n",
    "Epoch 25/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0560 - acc: 0.6671 - val_loss: 1.3684 - val_acc: 0.6068\n",
    "Epoch 26/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0461 - acc: 0.6702 - val_loss: 1.3782 - val_acc: 0.6065\n",
    "Epoch 27/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0385 - acc: 0.6720 - val_loss: 1.3897 - val_acc: 0.6054\n",
    "Epoch 28/30\n",
    "600000/600000 [==============================] - 492s - loss: 1.0295 - acc: 0.6749 - val_loss: 1.3945 - val_acc: 0.6053\n",
    "Epoch 29/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.0213 - acc: 0.6774 - val_loss: 1.4086 - val_acc: 0.6054\n",
    "Epoch 30/30\n",
    "600000/600000 [==============================] - 493s - loss: 1.0134 - acc: 0.6792 - val_loss: 1.4139 - val_acc: 0.6052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "json_string = model1.to_json()\n",
    "open(path + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model1.save_weights(path + 'models/w_' + model_name + '.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'text_generation_model1'\n",
    "\n",
    "model1 = model_from_json(open(path + 'models/mdl_' + model_name + '.json').read())\n",
    "model1.load_weights(path + 'models/w_' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "\n",
    "def sample(a, diversity=1.0):\n",
    "    '''\n",
    "    helper function to sample an index from a probability array\n",
    "    - Diversity control the level of randomless\n",
    "    '''\n",
    "    a = np.log(a) / diversity\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def generate_text(sentence, diversity, current_model, num_char=400):\n",
    "    sentence_init = sentence\n",
    "    generated = ''\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        preds = current_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print('\\n\\nDIVERSITY: ',diversity,'\\n')\n",
    "    print(sentence_init + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "mire vuestra merced de parecer que el mundo se ha de aquí a su ama, y el cura se le pasaba de la manera, que no se le pareció que está en el mundo de la vida, que es la mayor y me pareció que estaba de mi casa, y el que está en el mundo y a la señora dulcinea del toboso y el caballero de la triste figura, y el caballero de la triste figura, que era la venta la duquesa de la caballería, que es lo que se le dije\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "mire vuestra merced parece, pues, la cual es mejor que se entre las manos y de cabeza de parecer al principio en el cuerpo, y con esto le dijo:\n",
      "\n",
      "-señor don quijote, y el cura y el mal tal de la mancha, por la cual se le dijese que su amo de más se lo hayan.\n",
      "\n",
      "-por esto se puede ser de los de las mismas cosas más a su ama. si estaba diciendo que estaba de tanto camino para ser una grande amiga de la andante caba\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "mire vuestra merced luego, que de aquel alitado rico cuándo\n",
      "visto, y vino en su caballo.\n",
      "\n",
      "-en todo eso, vienes sumos los ancallar y bemas como ver la misma manera que a un fungísimo consejo\n",
      "cuando ninguno nodulan.bidor los hilos que los acometemos, o para mejor que me ha de aquí la tendida lotoria, y así,\n",
      "no vuestra merced ha dicho y todos caballeros andantes; la tres principales\n",
      "metidos; que, estando piens\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "mire vuestra merced -dijo el autor había mucho grande rodel de las armas; y, menos la nombre como si le quiso modo\n",
      "ni hasta que, para mostrar lo que ordenaba prosiguió sancho; porque de sobre la gigante génera el fue\n",
      "con su pecho.\n",
      "\n",
      "esto más le responda de tigas; y vimos su amentura; la cual, habían sido pasamientos, que ya tengo o\n",
      "déndolo.\n",
      "\n",
      "-sea mandado, hacer el revertado dello,    oyemon tus vuestras\n",
      "\n",
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "de lo que sucedió a la venta, en la cual se le dijese la ventera de la mancha, y la poca perdición que se le pareció que está en el camino para ser de la mancha, y la comedia se le perdieron a su señora, que es el mundo que está en la mano, y con las manos de la mancha, por estar a mi casa, se le pareció que allí no se le había de haber\n",
      "contento a la vista y de la mano de la caballería, y así lo había de\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "de lo que sucedió a la venta, y con la tierra su parte en la mano, y así, comenzó a sancho que el cura quedaba de la alta manda, y que los míos de la triste figura le hacía, que es el mundo que hay en el mundo que puro y tengo visto, porque el\n",
      "mono en la cabeza de la alta princesa del caso, y el contrario se pusieron en la aldea de caballerías, que allí los mayores y milagros en este pensamiento por de sus ar\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "de lo que sucedió a una\n",
      "   la virtud verdad que\n",
      "sota tan salida a entendido, de\n",
      "su tiempo sancho a esto el duque y el ánimo\n",
      "se lo pudiere decir a mis poderas, natural de\n",
      "valenconcella, mila, convenía que puede ser marqués por sus humanos armistemente y como por dios en tu costa dicísimo poeta, porque se mate de su\n",
      "linaje por el pensamiento, pues yo sayé toda tales pensao\n",
      "que no era menester\n",
      "para el cura\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "de lo que sucedió a buerandamente dorotea, y que más muerto, arrojo. digo, traistes vistos y no serás sonetos,\n",
      "sois escuderos que me\n",
      "cabaló el cuerpo se olvigan, de mandar como el soldado, y\n",
      "vasaun secleo, cinto la causa que\n",
      "nos ha oyendo en aquella gana y historia de viento, pues sombra hubo le trojado de noimeria, y a la\n",
      "menosbaraban de dios que andaba del salido envialmento, en\n",
      "la lilma teas y la fabola \n",
      "('\\n\\nDIVERSITY: ', 0.2, '\\n')\n",
      "de allí a poco comenzaron a dicio que la de las manos de la mancha, que es la de las manos de la mancha, allí hablada y de las mejores y miserables manos de la mancha, el cual, por la mesa de las letras, y que el señor mandaros a los que la de la mancha que la de las manos de su escudero, y que el que le pareció que está en el camino para despertar de los pensamientos y de la cabeza y para que se le había de ha\n",
      "('\\n\\nDIVERSITY: ', 0.5, '\\n')\n",
      "de allí a poco comenzaron a probar el apustió la cabeza y con el\n",
      "mundo. y así, le dijo:\n",
      "\n",
      "-eso no haré todo esto dejó la mitad del camino admirado que se le dejase de mi vida -replicó don quijote-; y, con todo eso, y caballero llamado como el acompañamiento, que de tu pregunta se le pasase de la mula y el torte para del mundo y se dos faltan a todos los que llaman palabras de sus intenciones de todos los que\n",
      "('\\n\\nDIVERSITY: ', 1, '\\n')\n",
      "de allí a poco comenzó conmigo; y a lo menes, será en sola suya que esto es pelo, fea de no estáramos así:\n",
      "\n",
      "hiciéramele, de alta por ocustra caballería; y así, lleétese,\n",
      "con alzón todo.\n",
      "\n",
      "-no deslaríamos el ercote, como si atribo de sus intentos para les provecho, nos\n",
      "hubieran hallado su honestidad como si\n",
      "llevaste -dijo don quijote-. sancho hijo, amigo, que lo será en las casas y mandaron los\n",
      "hida\n",
      "('\\n\\nDIVERSITY: ', 1.2, '\\n')\n",
      "de allí a poco comenzaron a sustentor y ofrecimiento al mabelaso el gente que para dín. entre él entierra muchas muchos atisma, que no la\n",
      "dejaría matro, me será que doléis en la casa\n",
      "de miente por remedio al de\n",
      "los pedradares, y no vista ladrón de vino en lo necesidad de cera\n",
      "pil brencia con la humidad de unos balcospes de alguna\n",
      "alcorjapa. ahora ya estoy, con con buenes nocheber, ni\n",
      "menomos más primero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = 'mire vuestra merced '\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de lo que sucedió a'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'de allí a poco come'\n",
    "generate_text(sentence, 0.2, model1)\n",
    "generate_text(sentence, 0.5, model1)\n",
    "generate_text(sentence, 1,   model1)\n",
    "generate_text(sentence, 1.2, model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TensorVariable' object has no attribute 'get_output_shape_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-58cf25fe8c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Combine input with output of first recurrent layer as input od second recurrent layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmerge1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_prev_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforwards1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Second forwards layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jorge/anaconda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m   1120\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jorge/anaconda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m             \u001b[0mlayer_output_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0;31m# case: the layer has multiple output tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorVariable' object has no attribute 'get_output_shape_at'"
     ]
    }
   ],
   "source": [
    "# Build a second model more complex\n",
    "# - 2 stacked LSTM. Direct connections  and more regularization.\n",
    "# - Direc connetions\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Merge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Build model 2')\n",
    "seq_prev_input = Input(shape=(maxlen, len(chars)), name='prev') \n",
    "                \n",
    "# apply forwards LSTM\n",
    "forwards1 = LSTM(1024, return_sequences=True)(seq_prev_input)\n",
    "dp_forwards1 = Dropout(0.5)(forwards1)\n",
    "\n",
    "# Combine input with output of first recurrent layer as input od second recurrent layer\n",
    "merge1 = Merge([seq_prev_input, forwards1], mode='concat', concat_axis=-1)\n",
    "\n",
    "# Second forwards layer\n",
    "forwards2 = LSTM(512, return_sequences=False)(merge1)\n",
    "dp_forwards2 = Dropout(0.5)(forwards2)\n",
    "\n",
    "# Combine output of the 2 recurrent layers.\n",
    "# Select the last sequence output of the first LSTM layer\n",
    "merge2 = Merge([dp_forwards1[:,-1,:], dp_forwards2], mode='concat', concat_axis=-1)\n",
    "\n",
    "output = Dense(len(chars), activation='softmax')(merge2)\n",
    "\n",
    "model2 = Model(input=seq_prev_input, output=output)\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "#Pending connect direct inputs to direct outputs and show graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Import mnist dataset and rescale between [0,1]\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(np.max(X_train[0]))\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Images (InputLayer)              (None, 28, 28)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Flat image (Flatten)             (None, 784)           0           Images[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "Dense output (Dense)             (None, 10)            7850        Flat image[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7850\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "print('Linear model')\n",
    "images = Input(batch_shape=(None, 28, 28), dtype='float32', name='Images') \n",
    "flat = Flatten(name='Flat image')(images)\n",
    "output = Dense(10, activation='softmax', name='Dense output')(flat)\n",
    "\n",
    "# Model Architecture defined\n",
    "model_linear = Model(input=images, output=output)\n",
    "model_linear.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model and select optimizer\n",
    "from keras.optimizers import sgd\n",
    "\n",
    "sgd_optimizer = sgd(lr=0.01)\n",
    "model_linear.compile(loss='sparse_categorical_crossentropy', \n",
    "                     optimizer=sgd_optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 0s - loss: 1.5827 - acc: 0.6098 - val_loss: 1.1098 - val_acc: 0.7886\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.9538 - acc: 0.8103 - val_loss: 0.8062 - val_acc: 0.8351\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.7584 - acc: 0.8362 - val_loss: 0.6777 - val_acc: 0.8535\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.6623 - acc: 0.8484 - val_loss: 0.6050 - val_acc: 0.8647\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.6038 - acc: 0.8571 - val_loss: 0.5578 - val_acc: 0.8713\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.5638 - acc: 0.8627 - val_loss: 0.5240 - val_acc: 0.8755\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.5344 - acc: 0.8675 - val_loss: 0.4985 - val_acc: 0.8795\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.5116 - acc: 0.8709 - val_loss: 0.4786 - val_acc: 0.8817\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4934 - acc: 0.8742 - val_loss: 0.4624 - val_acc: 0.8829\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4783 - acc: 0.8767 - val_loss: 0.4488 - val_acc: 0.8854\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4657 - acc: 0.8791 - val_loss: 0.4373 - val_acc: 0.8888\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4548 - acc: 0.8812 - val_loss: 0.4275 - val_acc: 0.8901\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4454 - acc: 0.8831 - val_loss: 0.4191 - val_acc: 0.8917\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4371 - acc: 0.8844 - val_loss: 0.4114 - val_acc: 0.8929\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4298 - acc: 0.8860 - val_loss: 0.4047 - val_acc: 0.8940\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4232 - acc: 0.8872 - val_loss: 0.3988 - val_acc: 0.8952\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4173 - acc: 0.8885 - val_loss: 0.3933 - val_acc: 0.8960\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4119 - acc: 0.8895 - val_loss: 0.3884 - val_acc: 0.8966\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4070 - acc: 0.8909 - val_loss: 0.3838 - val_acc: 0.8975\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.4024 - acc: 0.8917 - val_loss: 0.3798 - val_acc: 0.8975\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3983 - acc: 0.8923 - val_loss: 0.3759 - val_acc: 0.8986\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3944 - acc: 0.8932 - val_loss: 0.3724 - val_acc: 0.8996\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3908 - acc: 0.8939 - val_loss: 0.3691 - val_acc: 0.9005\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3874 - acc: 0.8951 - val_loss: 0.3662 - val_acc: 0.9011\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3843 - acc: 0.8955 - val_loss: 0.3631 - val_acc: 0.9014\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3813 - acc: 0.8962 - val_loss: 0.3605 - val_acc: 0.9026\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3785 - acc: 0.8968 - val_loss: 0.3579 - val_acc: 0.9033\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3759 - acc: 0.8974 - val_loss: 0.3554 - val_acc: 0.9039\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3734 - acc: 0.8981 - val_loss: 0.3532 - val_acc: 0.9044\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 0s - loss: 0.3710 - acc: 0.8984 - val_loss: 0.3512 - val_acc: 0.9055\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 256\n",
    "nb_epoch = 30\n",
    "\n",
    "history = model_linear.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHfCAYAAABwGPAaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd2acbda10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['val_acc'], label='val acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Images (InputLayer)              (None, 28, 28)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 28, 28)     0           Images[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 20, 24, 24)    520         reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 20, 12, 12)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 50, 8, 8)      25050       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 50, 4, 4)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "Flat image (Flatten)             (None, 800)           0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "Dense 1 (Dense)                  (None, 500)           400500      Flat image[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "Dense output (Dense)             (None, 10)            5010        Dense 1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 431080\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Convolutional model\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Convolution2D, Reshape, MaxPooling2D, Dropout\n",
    "from keras.optimizers import sgd\n",
    "\n",
    "print('Linear model')\n",
    "images = Input(batch_shape=(None, 28, 28), dtype='float32', name='Images') \n",
    "images_reshaped = Reshape((1,28,28))(images)\n",
    "\n",
    "#First convolution layers stack\n",
    "conv1 = Convolution2D(20, 5, 5)(images_reshaped)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "#Second convolution layers stack\n",
    "conv2 = Convolution2D(50, 5, 5)(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "#Flatten and dense layers\n",
    "flat = Flatten(name='Flat image')(pool2)\n",
    "dense1 = Dense(500, activation='relu', name='Dense 1')(flat)\n",
    "\n",
    "output = Dense(10, activation='softmax', name='Dense output')(dense1)\n",
    "\n",
    "# Model Architecture defined\n",
    "model_conv = Model(input=images, output=output)\n",
    "model_conv.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model and select optimizer\n",
    "sgd_optimizer = sgd(lr=0.01, momentum=0.99, decay=0.005, nesterov=True)\n",
    "model_conv.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.4263 - acc: 0.8892 - val_loss: 0.0974 - val_acc: 0.9715\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0729 - acc: 0.9788 - val_loss: 0.0496 - val_acc: 0.9851\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0360 - acc: 0.9897 - val_loss: 0.0378 - val_acc: 0.9885\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0233 - acc: 0.9927 - val_loss: 0.0374 - val_acc: 0.9884\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0162 - acc: 0.9954 - val_loss: 0.0343 - val_acc: 0.9892\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0124 - acc: 0.9968 - val_loss: 0.0354 - val_acc: 0.9889\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0362 - val_acc: 0.9892\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0368 - val_acc: 0.9890\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0062 - acc: 0.9989 - val_loss: 0.0372 - val_acc: 0.9889\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0368 - val_acc: 0.9897\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0370 - val_acc: 0.9891\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0045 - acc: 0.9993 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0382 - val_acc: 0.9885\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0384 - val_acc: 0.9891\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0037 - acc: 0.9995 - val_loss: 0.0383 - val_acc: 0.9891\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0384 - val_acc: 0.9892\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0388 - val_acc: 0.9889\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0393 - val_acc: 0.9892\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0391 - val_acc: 0.9894\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0396 - val_acc: 0.9894\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0394 - val_acc: 0.9892\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0400 - val_acc: 0.9893\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0025 - acc: 0.9998 - val_loss: 0.0399 - val_acc: 0.9893\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0024 - acc: 0.9998 - val_loss: 0.0404 - val_acc: 0.9894\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0024 - acc: 0.9998 - val_loss: 0.0406 - val_acc: 0.9891\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0406 - val_acc: 0.9891\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0409 - val_acc: 0.9894\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0407 - val_acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 256\n",
    "nb_epoch = 30\n",
    "history = model_conv.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 972    0    1    0    0    0    1    2    3    1]\n",
      " [   0 1128    1    1    0    0    1    2    2    0]\n",
      " [   2    0 1019    1    1    0    1    4    4    0]\n",
      " [   0    0    1 1000    0    4    0    1    2    2]\n",
      " [   0    0    0    0  972    0    2    1    0    7]\n",
      " [   2    0    0    6    0  881    1    1    1    0]\n",
      " [   2    2    0    0    1    2  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1015    1    5]\n",
      " [   2    0    2    1    0    1    0    0  964    4]\n",
      " [   0    0    0    3    7    2    0    3    2  992]]\n"
     ]
    }
   ],
   "source": [
    "# Score and select prediction with max prob\n",
    "import numpy as np\n",
    "pred_test = np.argmax(model_conv.predict(X_test), axis=1)\n",
    "\n",
    "#Evaluate the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data preprocessing\n",
    "    - Download data in the server\n",
    "    - Convert test to sequences.\n",
    "    - Configure sequences for a RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Download data in the server\n",
    "\n",
    "### Command line in the server\n",
    "    Path to data:\n",
    "        cd /home/ubuntu/data/training/keras\n",
    "    Download dataset: \n",
    "        wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    Uncompress it:\n",
    "        tar -zxvf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert test to sequences\n",
    "    - List of all text files\n",
    "    - Read files into python\n",
    "    - Tokenize\n",
    "    - Create dictionaries to recode\n",
    "    - Recode tokens into ids and create sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Imports and paths\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_path='/home/ubuntu/data/training/keras/aclImdb/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generator of list of files in a folder and subfolders\n",
    "import os\n",
    "import shutil\n",
    "import fnmatch\n",
    "\n",
    "def gen_find(filepattern, toppath):\n",
    "    '''\n",
    "    Generator with a recursive list of files in the toppath that match filepattern \n",
    "    Inputs:\n",
    "        filepattern(str): Command stype pattern \n",
    "        toppath(str): Root path\n",
    "    '''\n",
    "    for path, dirlist, filelist in os.walk(toppath):\n",
    "        for name in fnmatch.filter(filelist, filepattern):\n",
    "            yield os.path.join(path, name)\n",
    "\n",
    "#Test\n",
    "#print(gen_find(\"*.txt\", data_path+'train/pos/').next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michael Is King. This film contains some of the best stuff Mike has ever done. Smooth Criminal is pure genius. The cameos are wonderful, but as always, the main event is MJ himself. He is the best, hands down.', 'This comment does contain spoilers!!<br /><br />There are few actors that have an intangible to them. That innate quality which is an amalgamation of charisma, panache and swagger. It\\'s the quality that can separate good actors from the truly great. I think George Clooney has it and so does Jack Nicholson. You can look at Clooney\\'s subtle touches in scenes like his one word good-bye to Andy Garcia in Ocean\\'s 11 when they just utter each other\\'s name disdainfully. \"Terry.\" \"Danny.\" You can pick any number of Jack\\'s performances dating as far back as Five Easy Pieces in the diner to A Few Good Men and his court room interrogation scene. These guys just have it. You can add Denzel Washington to the small and exclusive list of actors who exudes that terrific trait in everything he does. If you look at some of his explosive borderline diatribes in The Siege to his impressive tribute to Malcolm X in Spike Lee\\'s film of the same name, you can see that there is no finer an actor working today. I don\\'t mention all of this to insinuate that Man On Fire is perfect just because of Denzel\\'s work, but he is definitely the cog of the production. I was literally mesmerized with some of his scenes that are raw, emotional and incendiary all at the same time.<br /><br />Washington plays Creasy a former spy or CIA agent or one of those covert government operatives. He has pretty much hit rock bottom as he has become disillusioned with the life that he has led. He has killed and perhaps done things that are best left unsaid and this has made him a hardened and bitter man. His friend and perhaps mentor, played very reservedly by Christopher Walken, is living in Mexico making a very comfortable living by providing body guard services for the rich. Apparently the kidnapping business in Mexico is so vibrant that these paid former S.E.A.L.s and such can do very well while providing a needed service. Creasey needs the work and accepts a job with a well to do family who seems to be in some financial difficulty. Marc Anthony is fine as Samuel, Radha Mitchell is tantalizingly sexy as his wife Lisa and Dakota Fanning is just unbelievably and precociously brilliant as Pita. I don\\'t know how a child of her age can have such range to play the characters that she does but her interpretation of Pita is nothing short of Oscar worthy. The film\\'s entire first half is dependent on the relationship between Pita and Creasy and if there was a weaker actress in the role, perhaps that emotional synergy would not have come across so succinctly. But Fanning is nothing short of remarkable in the role.<br /><br />It is the relationship between Pita and Creasy that drives this film to the apex of cinema. Together they are perfect and there is a real bond developed between them. Tony Scott directs with a frenetic urgency and his eye for visual flare has never been better. I am interested to see how his next film, Domino, turns out. I think Scott is one of today\\'s under rated directors and with more films like this one, his name will surely be elevated to icon status.<br /><br />The story has Creasy really taking to Pita, and vis-ca versa. There is a definite connection between the two of them and perhaps it stems from the fact that although Pita loves her dad, he is not around much. He is a philanthropist and obviously has little time to spend with his family. Soon, Creasy is taking Pita to her swimming competition. He is reading her bedtime stories and she is naming her teddy bear \"Creasy\". It\\'s not just a friendship between them, it is more of a kinship, and a deep parental love seems to be present. <br /><br />The film changes gears when Pita does get kidnapped and held for ransom and Creasy is is almost fatally injured trying to protect her. This is where the story becomes thick with innuendo and ripe with deceit as the plot pieces get unraveled like an onion. And this is where Denzel becomes a tour de force. Like I said earlier, I have seen Denzel give some outstanding performances in films like Crimson Tide and Training Day, but never have I seen him like this. He is a man possessed and with the possibility of Pita being dead, he becomes a literal man on fire. It rages in him as he hunts down and dishes out his brand of comeuppance. Denzel\\'s anger and acerbity are ubiquitous and not easily quelled as he hunts down each person responsible for Pita\\'s violation. This all vigilante justice as the Mexican authorities always seem to be one step behind. <br /><br />Also what is paramount to this film\\'s audacious brilliance is that there are few films that actually give the criminals their due comeuppance. I have often been frustrated to watch films where the bad guys get let off easily. They inflict all kinds of torment for the entire film and then they take a bullet and die. But not in this film. Writer Brian Helgeland sees to it that retribution here is unequivocal and it is painful. The perpetrators here feel Creasy\\'s wrath and they experience the torment that he unleashes. There is nothing gimmicky about his brand of justice. He needs information and someone loses a finger. He wants answers and a homemade bomb is placed in places that are meant for other things. There is no punches pulled here and this is one of the true strengths of the film.<br /><br />Man on Fire is one the five best films of 2004. Now that it is out on DVD, my recommendation is to get the SE. It is loaded with bonus features that include about 6 hours of documentaries and different commentary tracks. 10/10']\n"
     ]
    }
   ],
   "source": [
    "def read_sentences(path):\n",
    "    sentences = []\n",
    "    sentences_list = gen_find(\"*.txt\", path)\n",
    "    for ff in sentences_list:\n",
    "        with open(ff, 'r') as f:\n",
    "            sentences.append(f.readline().strip())\n",
    "    return sentences        \n",
    "\n",
    "#Test\n",
    "print(read_sentences(data_path+'train/pos/')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"After Chaplin made one of his best films: Dough & Dynamite, he made one of his worst: Gentlemen Of Nerve. During this first year in films, Chaplin made about a third of all his films. Many of them were experimental in terms of ad-libbing, editing, gags, location shooting, etc. This one takes place at a racetrack where Chaplin and his friend try to get in without paying. Mabel Normand is there with her friend also, and Chaplin manages to rid himself of both his and Mabel's friends. He then woos Mabel in the grandstand with no apparent repercussions from his behavior. Lots of slapstick in here, but there is very little else to recommend this film for other then watching Chaplin develop. The print I saw was badly deteriorated, which may have affected its enjoyment. Charley Chase can be glimpsed. * of 4 stars.\", \"Please, for the love of God, don't watch it. Now saying that, I know what you're thinking, it can't be that bad can it? If everyone says it as bad as they say, I have to watch it! Don't do it! It'll be like looking at a horrible accident involving little babies and a gasoline tanker! You'll be scarred for life...the image will never leave you! I could only watch a half hour of this before becoming violently sick. The acting is the worst I've ever seen, and I've seen Barbwire!!! If you do risk ripping your eyes out and rent this movie...don't say I haven't warned you! The cover and storyline are a trap!! Zombies? Satire? Shaun of the Dead was great! This movie must be the same....right? NO!! The writing = crap directing = garbage acting = there was no acting. Still not convinced? Then forever your soul will be tormented!!!\"]\n"
     ]
    }
   ],
   "source": [
    "print(read_sentences(data_path+'train/neg/')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Done!\n",
      "[['Michael', 'Is', 'King', '.', 'This', 'film', 'contains', 'some', 'of', 'the', 'best', 'stuff', 'Mike', 'has', 'ever', 'done', '.', 'Smooth', 'Criminal', 'is', 'pure', 'genius', '.', 'The', 'cameos', 'are', 'wonderful', ',', 'but', 'as', 'always', ',', 'the', 'main', 'event', 'is', 'MJ', 'himself', '.', 'He', 'is', 'the', 'best', ',', 'hands', 'down', '.'], ['This', 'comment', 'does', 'contain', 'spoilers', '!', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'There', 'are', 'few', 'actors', 'that', 'have', 'an', 'intangible', 'to', 'them', '.', 'That', 'innate', 'quality', 'which', 'is', 'an', 'amalgamation', 'of', 'charisma', ',', 'panache', 'and', 'swagger', '.', 'It', \"'s\", 'the', 'quality', 'that', 'can', 'separate', 'good', 'actors', 'from', 'the', 'truly', 'great', '.', 'I', 'think', 'George', 'Clooney', 'has', 'it', 'and', 'so', 'does', 'Jack', 'Nicholson', '.', 'You', 'can', 'look', 'at', 'Clooney', \"'s\", 'subtle', 'touches', 'in', 'scenes', 'like', 'his', 'one', 'word', 'good-bye', 'to', 'Andy', 'Garcia', 'in', 'Ocean', \"'s\", '11', 'when', 'they', 'just', 'utter', 'each', 'other', \"'s\", 'name', 'disdainfully', '.', '``', 'Terry', '.', \"''\", '``', 'Danny', '.', \"''\", 'You', 'can', 'pick', 'any', 'number', 'of', 'Jack', \"'s\", 'performances', 'dating', 'as', 'far', 'back', 'as', 'Five', 'Easy', 'Pieces', 'in', 'the', 'diner', 'to', 'A', 'Few', 'Good', 'Men', 'and', 'his', 'court', 'room', 'interrogation', 'scene', '.', 'These', 'guys', 'just', 'have', 'it', '.', 'You', 'can', 'add', 'Denzel', 'Washington', 'to', 'the', 'small', 'and', 'exclusive', 'list', 'of', 'actors', 'who', 'exudes', 'that', 'terrific', 'trait', 'in', 'everything', 'he', 'does', '.', 'If', 'you', 'look', 'at', 'some', 'of', 'his', 'explosive', 'borderline', 'diatribes', 'in', 'The', 'Siege', 'to', 'his', 'impressive', 'tribute', 'to', 'Malcolm', 'X', 'in', 'Spike', 'Lee', \"'s\", 'film', 'of', 'the', 'same', 'name', ',', 'you', 'can', 'see', 'that', 'there', 'is', 'no', 'finer', 'an', 'actor', 'working', 'today', '.', 'I', 'do', \"n't\", 'mention', 'all', 'of', 'this', 'to', 'insinuate', 'that', 'Man', 'On', 'Fire', 'is', 'perfect', 'just', 'because', 'of', 'Denzel', \"'s\", 'work', ',', 'but', 'he', 'is', 'definitely', 'the', 'cog', 'of', 'the', 'production', '.', 'I', 'was', 'literally', 'mesmerized', 'with', 'some', 'of', 'his', 'scenes', 'that', 'are', 'raw', ',', 'emotional', 'and', 'incendiary', 'all', 'at', 'the', 'same', 'time.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Washington', 'plays', 'Creasy', 'a', 'former', 'spy', 'or', 'CIA', 'agent', 'or', 'one', 'of', 'those', 'covert', 'government', 'operatives', '.', 'He', 'has', 'pretty', 'much', 'hit', 'rock', 'bottom', 'as', 'he', 'has', 'become', 'disillusioned', 'with', 'the', 'life', 'that', 'he', 'has', 'led', '.', 'He', 'has', 'killed', 'and', 'perhaps', 'done', 'things', 'that', 'are', 'best', 'left', 'unsaid', 'and', 'this', 'has', 'made', 'him', 'a', 'hardened', 'and', 'bitter', 'man', '.', 'His', 'friend', 'and', 'perhaps', 'mentor', ',', 'played', 'very', 'reservedly', 'by', 'Christopher', 'Walken', ',', 'is', 'living', 'in', 'Mexico', 'making', 'a', 'very', 'comfortable', 'living', 'by', 'providing', 'body', 'guard', 'services', 'for', 'the', 'rich', '.', 'Apparently', 'the', 'kidnapping', 'business', 'in', 'Mexico', 'is', 'so', 'vibrant', 'that', 'these', 'paid', 'former', 'S.E.A.L.s', 'and', 'such', 'can', 'do', 'very', 'well', 'while', 'providing', 'a', 'needed', 'service', '.', 'Creasey', 'needs', 'the', 'work', 'and', 'accepts', 'a', 'job', 'with', 'a', 'well', 'to', 'do', 'family', 'who', 'seems', 'to', 'be', 'in', 'some', 'financial', 'difficulty', '.', 'Marc', 'Anthony', 'is', 'fine', 'as', 'Samuel', ',', 'Radha', 'Mitchell', 'is', 'tantalizingly', 'sexy', 'as', 'his', 'wife', 'Lisa', 'and', 'Dakota', 'Fanning', 'is', 'just', 'unbelievably', 'and', 'precociously', 'brilliant', 'as', 'Pita', '.', 'I', 'do', \"n't\", 'know', 'how', 'a', 'child', 'of', 'her', 'age', 'can', 'have', 'such', 'range', 'to', 'play', 'the', 'characters', 'that', 'she', 'does', 'but', 'her', 'interpretation', 'of', 'Pita', 'is', 'nothing', 'short', 'of', 'Oscar', 'worthy', '.', 'The', 'film', \"'s\", 'entire', 'first', 'half', 'is', 'dependent', 'on', 'the', 'relationship', 'between', 'Pita', 'and', 'Creasy', 'and', 'if', 'there', 'was', 'a', 'weaker', 'actress', 'in', 'the', 'role', ',', 'perhaps', 'that', 'emotional', 'synergy', 'would', 'not', 'have', 'come', 'across', 'so', 'succinctly', '.', 'But', 'Fanning', 'is', 'nothing', 'short', 'of', 'remarkable', 'in', 'the', 'role.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'It', 'is', 'the', 'relationship', 'between', 'Pita', 'and', 'Creasy', 'that', 'drives', 'this', 'film', 'to', 'the', 'apex', 'of', 'cinema', '.', 'Together', 'they', 'are', 'perfect', 'and', 'there', 'is', 'a', 'real', 'bond', 'developed', 'between', 'them', '.', 'Tony', 'Scott', 'directs', 'with', 'a', 'frenetic', 'urgency', 'and', 'his', 'eye', 'for', 'visual', 'flare', 'has', 'never', 'been', 'better', '.', 'I', 'am', 'interested', 'to', 'see', 'how', 'his', 'next', 'film', ',', 'Domino', ',', 'turns', 'out', '.', 'I', 'think', 'Scott', 'is', 'one', 'of', 'today', \"'s\", 'under', 'rated', 'directors', 'and', 'with', 'more', 'films', 'like', 'this', 'one', ',', 'his', 'name', 'will', 'surely', 'be', 'elevated', 'to', 'icon', 'status.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'story', 'has', 'Creasy', 'really', 'taking', 'to', 'Pita', ',', 'and', 'vis-ca', 'versa', '.', 'There', 'is', 'a', 'definite', 'connection', 'between', 'the', 'two', 'of', 'them', 'and', 'perhaps', 'it', 'stems', 'from', 'the', 'fact', 'that', 'although', 'Pita', 'loves', 'her', 'dad', ',', 'he', 'is', 'not', 'around', 'much', '.', 'He', 'is', 'a', 'philanthropist', 'and', 'obviously', 'has', 'little', 'time', 'to', 'spend', 'with', 'his', 'family', '.', 'Soon', ',', 'Creasy', 'is', 'taking', 'Pita', 'to', 'her', 'swimming', 'competition', '.', 'He', 'is', 'reading', 'her', 'bedtime', 'stories', 'and', 'she', 'is', 'naming', 'her', 'teddy', 'bear', '``', 'Creasy', \"''\", '.', 'It', \"'s\", 'not', 'just', 'a', 'friendship', 'between', 'them', ',', 'it', 'is', 'more', 'of', 'a', 'kinship', ',', 'and', 'a', 'deep', 'parental', 'love', 'seems', 'to', 'be', 'present', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'film', 'changes', 'gears', 'when', 'Pita', 'does', 'get', 'kidnapped', 'and', 'held', 'for', 'ransom', 'and', 'Creasy', 'is', 'is', 'almost', 'fatally', 'injured', 'trying', 'to', 'protect', 'her', '.', 'This', 'is', 'where', 'the', 'story', 'becomes', 'thick', 'with', 'innuendo', 'and', 'ripe', 'with', 'deceit', 'as', 'the', 'plot', 'pieces', 'get', 'unraveled', 'like', 'an', 'onion', '.', 'And', 'this', 'is', 'where', 'Denzel', 'becomes', 'a', 'tour', 'de', 'force', '.', 'Like', 'I', 'said', 'earlier', ',', 'I', 'have', 'seen', 'Denzel', 'give', 'some', 'outstanding', 'performances', 'in', 'films', 'like', 'Crimson', 'Tide', 'and', 'Training', 'Day', ',', 'but', 'never', 'have', 'I', 'seen', 'him', 'like', 'this', '.', 'He', 'is', 'a', 'man', 'possessed', 'and', 'with', 'the', 'possibility', 'of', 'Pita', 'being', 'dead', ',', 'he', 'becomes', 'a', 'literal', 'man', 'on', 'fire', '.', 'It', 'rages', 'in', 'him', 'as', 'he', 'hunts', 'down', 'and', 'dishes', 'out', 'his', 'brand', 'of', 'comeuppance', '.', 'Denzel', \"'s\", 'anger', 'and', 'acerbity', 'are', 'ubiquitous', 'and', 'not', 'easily', 'quelled', 'as', 'he', 'hunts', 'down', 'each', 'person', 'responsible', 'for', 'Pita', \"'s\", 'violation', '.', 'This', 'all', 'vigilante', 'justice', 'as', 'the', 'Mexican', 'authorities', 'always', 'seem', 'to', 'be', 'one', 'step', 'behind', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Also', 'what', 'is', 'paramount', 'to', 'this', 'film', \"'s\", 'audacious', 'brilliance', 'is', 'that', 'there', 'are', 'few', 'films', 'that', 'actually', 'give', 'the', 'criminals', 'their', 'due', 'comeuppance', '.', 'I', 'have', 'often', 'been', 'frustrated', 'to', 'watch', 'films', 'where', 'the', 'bad', 'guys', 'get', 'let', 'off', 'easily', '.', 'They', 'inflict', 'all', 'kinds', 'of', 'torment', 'for', 'the', 'entire', 'film', 'and', 'then', 'they', 'take', 'a', 'bullet', 'and', 'die', '.', 'But', 'not', 'in', 'this', 'film', '.', 'Writer', 'Brian', 'Helgeland', 'sees', 'to', 'it', 'that', 'retribution', 'here', 'is', 'unequivocal', 'and', 'it', 'is', 'painful', '.', 'The', 'perpetrators', 'here', 'feel', 'Creasy', \"'s\", 'wrath', 'and', 'they', 'experience', 'the', 'torment', 'that', 'he', 'unleashes', '.', 'There', 'is', 'nothing', 'gimmicky', 'about', 'his', 'brand', 'of', 'justice', '.', 'He', 'needs', 'information', 'and', 'someone', 'loses', 'a', 'finger', '.', 'He', 'wants', 'answers', 'and', 'a', 'homemade', 'bomb', 'is', 'placed', 'in', 'places', 'that', 'are', 'meant', 'for', 'other', 'things', '.', 'There', 'is', 'no', 'punches', 'pulled', 'here', 'and', 'this', 'is', 'one', 'of', 'the', 'true', 'strengths', 'of', 'the', 'film.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Man', 'on', 'Fire', 'is', 'one', 'the', 'five', 'best', 'films', 'of', '2004', '.', 'Now', 'that', 'it', 'is', 'out', 'on', 'DVD', ',', 'my', 'recommendation', 'is', 'to', 'get', 'the', 'SE', '.', 'It', 'is', 'loaded', 'with', 'bonus', 'features', 'that', 'include', 'about', '6', 'hours', 'of', 'documentaries', 'and', 'different', 'commentary', 'tracks', '.', '10/10']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sentences):\n",
    "    from nltk import word_tokenize\n",
    "    print( 'Tokenizing...',)\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        tokens += [word_tokenize(sentence)]\n",
    "    print('Done!')\n",
    "\n",
    "    return tokens\n",
    "\n",
    "print(tokenize(read_sentences(data_path+'train/pos/')[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Done!\n",
      "Tokenizing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sentences_trn_pos = tokenize(read_sentences(data_path+'train/pos/'))\n",
    "sentences_trn_neg = tokenize(read_sentences(data_path+'train/neg/'))\n",
    "sentences_trn = sentences_trn_pos + sentences_trn_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary..\n",
      "7056193  total words  135098  unique words\n",
      "2 289298\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary to conver words to numbers. Order it with most frequent words first\n",
    "def build_dict(sentences):\n",
    "#    from collections import OrderedDict\n",
    "\n",
    "    '''\n",
    "    Build dictionary of train words\n",
    "    Outputs: \n",
    "     - Dictionary of word --> word index\n",
    "     - Dictionary of word --> word count freq\n",
    "    '''\n",
    "    print( 'Building dictionary..',)\n",
    "    wordcount = dict()\n",
    "    #For each worn in each sentence, cummulate frequency\n",
    "    for ss in sentences:\n",
    "        for w in ss:\n",
    "            if w not in wordcount:\n",
    "                wordcount[w] = 1\n",
    "            else:\n",
    "                wordcount[w] += 1\n",
    "\n",
    "    counts = list(wordcount.values()) # List of frequencies\n",
    "    keys = list(wordcount) #List of words\n",
    "    \n",
    "    sorted_idx = reversed(np.argsort(counts))\n",
    "    \n",
    "    worddict = dict()\n",
    "    for idx, ss in enumerate(sorted_idx):\n",
    "        worddict[keys[ss]] = idx+2  # leave 0 and 1 (UNK)\n",
    "    print( np.sum(counts), ' total words ', len(keys), ' unique words')\n",
    "\n",
    "    return worddict, wordcount\n",
    "\n",
    "\n",
    "worddict, wordcount = build_dict(sentences_trn)\n",
    "\n",
    "print(worddict['the'], wordcount['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "def generate_sequence(sentences, dictionary):\n",
    "    '''\n",
    "    Convert tokenized text in sequences of integers\n",
    "    '''\n",
    "    seqs = [None] * len(sentences)\n",
    "    for idx, ss in enumerate(sentences):\n",
    "        seqs[idx] = [dictionary[w] if w in dictionary else 1 for w in ss]\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492, 797, 778, 4, 61, 26, 1406, 62, 7, 2, 145, 567, 1944, 56, 147, 250, 4, 13398, 10409, 9, 1102, 1293, 4, 21, 3295, 35, 424, 3, 29, 22, 228, 3, 2, 305, 1557, 9, 9804, 326, 4, 154, 9, 2, 145, 3, 1002, 211, 4] 1\n"
     ]
    }
   ],
   "source": [
    "# Create train and test data\n",
    "\n",
    "#Read train sentences and generate target y\n",
    "train_x_pos = generate_sequence(sentences_trn_pos, worddict)\n",
    "train_x_neg = generate_sequence(sentences_trn_neg, worddict)\n",
    "X_train_full = train_x_pos + train_x_neg\n",
    "y_train_full = [1] * len(train_x_pos) + [0] * len(train_x_neg)\n",
    "\n",
    "print(X_train_full[0], y_train_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Done!\n",
      "Tokenizing...\n",
      "Done!\n",
      "[712, 17355, 18, 25, 1206, 1, 92, 392, 55, 49, 2, 174, 144, 3712, 97, 2, 2526, 7, 484, 36542, 14, 6, 11759, 14, 1418, 18044, 14, 2, 1466, 18, 4, 214, 228, 3, 17355, 3, 129, 2, 31532, 17, 40, 9, 3, 392, 8, 2, 6013, 94, 50, 45, 2, 366, 7, 38, 299, 4, 15, 183, 273, 19, 25, 4190, 44, 9154, 1582, 4, 15, 3099, 14, 2, 2819, 5, 71, 395, 2, 3064, 7, 2, 2478, 43, 101514, 2676, 28, 5264, 2050, 44, 62, 27, 53, 19, 25, 71, 136, 249, 599, 22, 88, 31672, 9893, 18288, 92, 4, 15, 121, 19, 9, 6, 63, 25, 72, 9, 64, 31532, 93, 16, 9, 771, 4, 118, 202, 3, 121, 7, 2, 74, 873, 16, 20, 109, 28, 9154, 27, 5, 67, 96, 39, 1657, 5, 319, 33, 26, 43, 17, 74, 4, 15, 37, 228, 273, 712, 17355, 8, 39, 2375, 736, 5, 65, 4609, 4, 15, 139, 131, 37, 8157, 2, 26, 22, 10973, 5, 1489, 2577, 4, 153, 34, 256, 19, 115, 3, 130, 31672, 9893, 18288, 92, 23, 2831, 765, 64672, 4, 15, 265, 6, 17355, 359, 5, 376, 2, 25, 24, 16, 18, 4118, 3, 36, 5479, 4, 214, 15, 37, 319, 3, 17355, 2505, 14, 19, 758, 5, 1596, 23165, 8, 393, 1535, 1582, 28, 1, 3, 1750, 2072, 3, 130033, 637, 27, 4, 565, 886, 171, 5, 376, 19, 42, 49, 6, 65, 7306, 1535, 74, 873, 14, 19, 758, 4, 422, 30, 39, 119, 37112, 7, 629, 17355, 4, 1627, 48614, 1, 1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Read test sentences and generate target y\n",
    "sentences_tst_pos = read_sentences(data_path+'test/pos/')\n",
    "sentences_tst_neg = read_sentences(data_path+'test/neg/')\n",
    "\n",
    "test_x_pos = generate_sequence(tokenize(sentences_tst_pos), worddict)\n",
    "test_x_neg = generate_sequence(tokenize(sentences_tst_neg), worddict)\n",
    "X_test_full = test_x_pos + test_x_neg\n",
    "y_test_full = [1] * len(test_x_pos) + [0] * len(test_x_neg)\n",
    "\n",
    "print(X_test_full[0])\n",
    "print(y_test_full[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Configure sequences for a RNN model\n",
    "    - Remove words with low frequency\n",
    "    - Truncate / complete sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median length:  208.0\n"
     ]
    }
   ],
   "source": [
    "#Median length of sentences\n",
    "print('Median length: ', np.median([len(x) for x in X_test_full]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_features = 50000 # Number of most frequent words selected. the less frequent recode to 0\n",
    "maxlen = 200  # cut texts after this number of words (among top max_features most common words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41650, 0, 178, 85, 11828, 3, 1613, 24, 85, 9074, 3, 16, 18, 6, 85, 1783, 23014, 5721, 33, 2, 5768, 4, 5746, 88, 30, 491, 78, 40, 17422, 3, 78, 40, 3303, 45, 151, 2132, 5, 1848, 3, 19, 9, 26, 276, 43, 16, 18366, 4, 51, 18, 106, 8, 84, 6, 26, 4035, 624, 179, 737, 9, 30, 1, 23, 44, 2, 2196, 17, 39, 4, 5746, 9, 6, 1749, 7, 8809, 28956, 70, 7057, 1116, 5, 1176, 7055, 16, 23, 499, 58, 1407, 399, 125, 34, 195, 36, 300, 78, 34, 156, 39, 317, 271, 14, 7106, 54, 3184, 206, 1111, 3, 379, 115, 16, 18, 6, 9440, 10182, 5, 42, 36, 8, 39, 1065, 41, 51, 18, 36, 24, 352, 5, 15, 167, 6805, 114, 4742, 99, 218, 2, 26, 3, 475, 78, 34, 195, 36, 6, 359, 7, 5746, 18, 460, 3, 19, 227, 39, 6, 140, 296, 8, 7136, 3, 29, 0, 3, 16, 9, 6, 26, 72, 353, 56, 8, 39, 128, 4, 401, 1369, 31079, 26, 359, 156, 1056, 19, 4, 124, 2, 257, 7, 0, 30066, 69, 834, 60, 30, 34, 3572, 2990, 104, 41, 41]\n"
     ]
    }
   ],
   "source": [
    "#Select the most frequent max_features, recode others using 0\n",
    "def remove_features(x):\n",
    "    return [[0 if w >= max_features else w for w in sen] for sen in x]\n",
    "\n",
    "X_train = remove_features(X_train_full)\n",
    "X_test  = remove_features(X_test_full)\n",
    "y_train = y_train_full\n",
    "y_test = y_test_full\n",
    "\n",
    "print(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 200)\n",
      "X_test shape: (25000, 200)\n",
      "[ 9154  1582     4    15  3099    14     2  2819     5    71   395     2\n",
      "  3064     7     2  2478    43     0  2676    28  5264  2050    44    62\n",
      "    27    53    19    25    71   136   249   599    22    88 31672  9893\n",
      " 18288    92     4    15   121    19     9     6    63    25    72     9\n",
      "    64 31532    93    16     9   771     4   118   202     3   121     7\n",
      "     2    74   873    16    20   109    28  9154    27     5    67    96\n",
      "    39  1657     5   319    33    26    43    17    74     4    15    37\n",
      "   228   273   712 17355     8    39  2375   736     5    65  4609     4\n",
      "    15   139   131    37  8157     2    26    22 10973     5  1489  2577\n",
      "     4   153    34   256    19   115     3   130 31672  9893 18288    92\n",
      "    23  2831   765     0     4    15   265     6 17355   359     5   376\n",
      "     2    25    24    16    18  4118     3    36  5479     4   214    15\n",
      "    37   319     3 17355  2505    14    19   758     5  1596 23165     8\n",
      "   393  1535  1582    28     1     3  1750  2072     3     0   637    27\n",
      "     4   565   886   171     5   376    19    42    49     6    65  7306\n",
      "  1535    74   873    14    19   758     4   422    30    39   119 37112\n",
      "     7   629 17355     4  1627 48614     1     1]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Cut or complete the sentences to length = maxlen\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Export train and test data\n",
    "np.save(data_path+'X_train', X_train)\n",
    "np.save(data_path+'y_train', y_train)\n",
    "np.save(data_path+'X_test', X_test)\n",
    "np.save(data_path+'y_test', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export worddict\n",
    "import pickle\n",
    "\n",
    "with open(data_path + 'worddict.pickle', 'wb') as pfile:\n",
    "    pickle.dump(worddict, pfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_tf1]",
   "language": "python",
   "name": "conda-env-py3_tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

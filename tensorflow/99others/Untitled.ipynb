{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn import metric_spec\n",
    "from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
    "from tensorflow.contrib.tensor_forest.client import eval_metrics\n",
    "from tensorflow.contrib.tensor_forest.client import random_forest\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#from tensorflow.python.platform import app\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "batch_size = 128\n",
    "model_dir = '/tmp/mnist/'\n",
    "num_trees = 10\n",
    "max_nodes = 10\n",
    "use_training_loss = True\n",
    "\n",
    "def build_estimator(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    params = tensor_forest.ForestHParams(\n",
    "        num_classes=10, num_features=784,\n",
    "        num_trees=num_trees, max_nodes=max_nodes)\n",
    "    \n",
    "    graph_builder_class = tensor_forest.RandomForestGraphs\n",
    "    \n",
    "    if use_training_loss:\n",
    "        graph_builder_class = tensor_forest.TrainingLossForest\n",
    "    \n",
    "    # Use the SKCompat wrapper, which gives us a convenient way to split\n",
    "    # in-memory data like MNIST into batches.\n",
    "    return estimator.SKCompat(random_forest.TensorForestEstimator(\n",
    "        params, graph_builder_class=graph_builder_class,\n",
    "        model_dir=model_dir))\n",
    "\n",
    "\n",
    "\"\"\"Train and evaluate the model.\"\"\"\n",
    "est = build_estimator(model_dir)\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/mnist/', one_hot=False)\n",
    "\n",
    "est.fit(x=mnist.train.images, y=mnist.train.labels, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorForestEstimator' object has no attribute '_evaluate_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8ca7c1347771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m results = est.score(x=mnist.test.images, y=mnist.test.labels,\n\u001b[1;32m      8\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                       metrics=metric)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jorge/anaconda3/envs/keras2_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, x, y, batch_size, steps, metrics)\u001b[0m\n\u001b[1;32m   1361\u001b[0m       raise ValueError('Metrics argument should be None or dict. '\n\u001b[1;32m   1362\u001b[0m                        'Got %s.' % metrics)\n\u001b[0;32m-> 1363\u001b[0;31m     eval_results, global_step = self._estimator._evaluate_model(\n\u001b[0m\u001b[1;32m   1364\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0mfeed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorForestEstimator' object has no attribute '_evaluate_model'"
     ]
    }
   ],
   "source": [
    "metric_name = 'accuracy'\n",
    "metric = {metric_name:\n",
    "            metric_spec.MetricSpec(\n",
    "                eval_metrics.get_metric(metric_name),\n",
    "                prediction_key=eval_metrics.get_prediction_key(metric_name))}\n",
    "\n",
    "results = est.score(x=mnist.test.images, y=mnist.test.labels,\n",
    "                      batch_size=batch_size,\n",
    "                      metrics=metric)\n",
    "for key in sorted(results):\n",
    "    print('%s: %s' % (key, results[key]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras2_py36]",
   "language": "python",
   "name": "conda-env-keras2_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

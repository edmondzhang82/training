{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to tensor flow\n",
    "    - Load MNIST dataset\n",
    "    - Linear model\n",
    "    - Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Basic libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "\n",
    "#Show images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt configuration\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # size of images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # show exact image\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Examine the data\n",
    "print('Train shape: ', mnist.train.images.shape)\n",
    "print('Valid shape: ', mnist.validation.images.shape)\n",
    "print('Test  shape: ', mnist.test.images.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(25):\n",
    "    a = fig.add_subplot(5,5,i+1)\n",
    "    a.set_title('Target: ' + str(np.argmax(mnist.train.labels[i])))\n",
    "    fig.tight_layout()\n",
    "    plt.imshow( np.reshape(mnist.train.images[i],(28,28)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start an interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "\n",
    "### Define the graph\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "#-----------   MODEL  ---------------\n",
    "#------------------------------------\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y_pred = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "#------------------------------------\n",
    "\n",
    "\n",
    "# Loss\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(y_pred))\n",
    "\n",
    "# Trainer\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "### Train the graph\n",
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Iterate running the trainer\n",
    "batch_size = 128\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    for i in range(430):  # 215 * batch_size is aprox the train size (55000)\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "    \n",
    "# Predict and evaluate    \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Test accuracy: ', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "    \n",
    "\n",
    "#When finish, close the interactive session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dense_layer(x, input_dim=10, output_dim=10, name='dense'):\n",
    "    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name='W_'+name)\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_dim]), name='b_'+name)\n",
    "    dense_output = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    return dense_output\n",
    "\n",
    "# Start an interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "\n",
    "### Define the graph\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "#-----------   MODEL  ---------------\n",
    "#------------------------------------\n",
    "# First layer\n",
    "dense_1 = dense_layer(x, input_dim=784, output_dim=500)\n",
    "\n",
    "# Final layer\n",
    "dense_2 = dense_layer(dense_1, input_dim=500, output_dim=10)\n",
    "y_pred = tf.nn.softmax(dense_2)\n",
    "#------------------------------------\n",
    "\n",
    "\n",
    "# Loss\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(y_pred))\n",
    "\n",
    "# Trainer\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# Predict and evaluate    \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "### Train the graph\n",
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# Iterate running the trainer\n",
    "batch_size = 128\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    for i in range(430):  # 430 * batch_size is aprox the train size (55000)\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "    print('Epoch: ',epoch,' - Accuracy: ', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "print('Test accuracy: ', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "    \n",
    "\n",
    "#When finish, close the interactive session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, size=2, input_channels=1, output_channels=32, name='conv'):\n",
    "    W_conv = tf.Variable(tf.truncated_normal([size, size, input_channels, output_channels], stddev=0.1), name='W_'+name)\n",
    "    b_conv = tf.Variable(tf.constant(0.1, shape=[output_channels]), name='b_'+name)\n",
    "    conv_out = tf.nn.relu(tf.nn.conv2d(x, W_conv, strides=[1, 1, 1, 1], padding='SAME') + b_conv)\n",
    "    return conv_out\n",
    "\n",
    "\n",
    "def dense_layer(x, input_dim=10, output_dim=10, name='dense'):\n",
    "    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name='W_'+name)\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_dim]), name='b_'+name)\n",
    "    dense_output = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    return dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start an interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "#Create the net\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "#-----------   MODEL  ---------------\n",
    "#------------------------------------\n",
    "#Reshape input data to the original image shape\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# First convolution\n",
    "h_conv1 = conv_layer(x_image, size=5, input_channels=1, output_channels=20, name='conv1')\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print('Conv - pool 1: ', h_pool1)\n",
    "\n",
    "#Second convolution\n",
    "h_conv2 = conv_layer(h_pool1, size=5, input_channels=20, output_channels=50, name='conv1')\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print('Conv - pool 2: ', h_pool2)\n",
    "\n",
    "#First dense layer\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*50])\n",
    "h_fc1 = dense_layer(h_pool2_flat, input_dim=7*7*50, output_dim=500, name='dense1')\n",
    "print('Dense 1: ', h_fc1)\n",
    "\n",
    "#Dropout over \n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, dropout_keep_prob)\n",
    "\n",
    "#Second dense layer\n",
    "h_fc2 = dense_layer(h_fc1_drop, input_dim=500, output_dim=10)\n",
    "print('Dense 2: ', h_fc2)\n",
    "\n",
    "#Prediction\n",
    "y_pred = tf.nn.softmax(h_fc2)\n",
    "#------------------------------------\n",
    "\n",
    "\n",
    "# Loss function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(h_fc2, y, name='cross_entropy')\n",
    "\n",
    "#Optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "#Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inicialization.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Train proccess\n",
    "for i in range(2000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1], dropout_keep_prob: 0.5})\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], dropout_keep_prob: 1})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_test = 0\n",
    "for i in range(200):\n",
    "    batch = mnist.test.next_batch(50)\n",
    "    acc_test += accuracy.eval(feed_dict = {x:batch[0], y: batch[1], dropout_keep_prob: 1.0})\n",
    "print(\"test accuracy: \", acc_test/200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tensorboard to show the net & the training process.\n",
    "    - The same previous convolutional model with the commands that need tensorboard\n",
    "\n",
    "Based on https://www.tensorflow.org/versions/r0.7/how_tos/summaries_and_tensorboard/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'   + name, mean)\n",
    "        tf.summary.scalar('sttdev/' + name, tf.sqrt(tf.reduce_mean(tf.square(var - mean))))\n",
    "        tf.summary.scalar('max/'    + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/'    + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, size=2, input_channels=1, output_channels=32, name='conv'):\n",
    "    W_conv = tf.Variable(tf.truncated_normal([size, size, input_channels, output_channels], stddev=0.1), name='W_'+name)\n",
    "    b_conv = tf.Variable(tf.constant(0.1, shape=[output_channels]), name='b_'+name)\n",
    "    conv_out = tf.nn.relu(tf.nn.conv2d(x, W_conv, strides=[1, 1, 1, 1], padding='SAME') + b_conv)\n",
    "    # Add summary ops to collect data\n",
    "    variable_summaries(W_conv, \"weights_\"+name) #TENSORBOARD\n",
    "    variable_summaries(b_conv, \"biases_\"+name) #TENSORBOARD\n",
    "    return conv_out\n",
    "\n",
    "\n",
    "def dense_layer(x, input_dim=10, output_dim=10, name='dense'):\n",
    "    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name='W_'+name)\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_dim]), name='b_'+name)\n",
    "    dense_output = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    variable_summaries(W, \"weights_\"+name) #TENSORBOARD\n",
    "    variable_summaries(b, \"biases_\"+name) #TENSORBOARD\n",
    "    return dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Start an interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "\n",
    "#Create the net\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10] , name='y')\n",
    "\n",
    "\n",
    "\n",
    "#Reshape input data to the original image shape\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# First convolution\n",
    "# use a name scope to organize nodes in the graph visualizer\n",
    "with tf.name_scope(\"conv1\") as scope:\n",
    "    h_conv1 = conv_layer(x_image, size=5, input_channels=1, output_channels=20, name='conv1')\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('Conv - pool 1: ', h_pool1)\n",
    "    # Add summary ops to collect data\n",
    "    variable_summaries(h_pool1, \"h_pool1_summary\") #TENSORBOARD\n",
    "\n",
    "#Second convolution\n",
    "with tf.name_scope(\"conv2\") as scope:\n",
    "    h_conv2 = conv_layer(h_pool1, size=5, input_channels=20, output_channels=50, name='conv2')\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('Conv - pool 2: ', h_pool2)\n",
    "    variable_summaries(h_pool2, \"h_pool2_summary\") #TENSORBOARD\n",
    "\n",
    "#First dense layer\n",
    "with tf.name_scope(\"dense1\") as scope:\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*50])\n",
    "    h_fc1 = dense_layer(h_pool2_flat, input_dim=7*7*50, output_dim=500, name='dense1')\n",
    "    variable_summaries(h_fc1, \"dense1_summary\") #TENSORBOARD\n",
    "\n",
    "    #Dropout over \n",
    "    dropout_keep_prob = tf.placeholder(tf.float32, name='dropout')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, dropout_keep_prob)\n",
    "    \n",
    "#Second dense layer\n",
    "with tf.name_scope(\"dense2\") as scope:\n",
    "    h_fc2 = dense_layer(h_fc1_drop, input_dim=500, output_dim=10, name='dense2')\n",
    "    print('Dense 2: ', h_fc2)\n",
    "    variable_summaries(h_fc2, \"dense2_summary\") #TENSORBOARD\n",
    "\n",
    "#Prediction\n",
    "y_pred = tf.nn.softmax(h_fc2)\n",
    "\n",
    "\n",
    "\n",
    "# Loss function\n",
    "with tf.name_scope(\"xent\") as scope:\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(h_fc2, y, name='cross_entropy')\n",
    "    ce_summ = tf.summary.histogram(\"cross entropy\", cross_entropy) #TENSORBOARD\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "#Accuracy\n",
    "with tf.name_scope(\"test\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy) #TENSORBOARD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge all the summaries and write it into /tmp/tensorboard/mnist_logs\n",
    "summaries_dir = '/tmp/tensorboard/mnist_conv'\n",
    "with tf.name_scope('summaries') as scope:\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "    test_writer  = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inicialization.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Train proccess\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1], dropout_keep_prob: 0.5})\n",
    "    \n",
    "    if i % 10 == 0:  # Record summary data for one batch\n",
    "        summary_str = merged.eval(feed_dict={x: batch[0], y: batch[1], dropout_keep_prob: 1.})\n",
    "        train_writer.add_summary(summary_str, i) #TENSORBOARD\n",
    "        \n",
    "        batch_test = mnist.test.next_batch(128)\n",
    "        summary_str = merged.eval(feed_dict={x: batch_test[0], y: batch_test[1], dropout_keep_prob: 1.})\n",
    "        test_writer.add_summary(summary_str, i) #TENSORBOARD\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end execute tensorboar with:\n",
    "\n",
    "    cd /tmp\n",
    "\n",
    "    tensorboard --logdir=./tensorboard\n",
    "\n",
    "And accest to it in:\n",
    "\n",
    "    http://localhost:6006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and save model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "\n",
    "# Start interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "# Define graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name='y')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "#Prediction\n",
    "y_pred = tf.nn.softmax(tf.matmul(x,W) + b, name='y_pred')\n",
    "\n",
    "#Loss\n",
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_pred), name='cross_entropy')\n",
    "\n",
    "# Train graph\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01, name='train_step').minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# Inicialize graph vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(100):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "# Predict and evaluate    \n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "print('cross_entropy test', cross_entropy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "print('Accuracy test', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "\n",
    "# Create a saver and save weigths.\n",
    "saver = tf.train.Saver(max_to_keep=0)\n",
    "saver.save(sess, '/tmp/my-model',)\n",
    "\n",
    "\n",
    "#Close session\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and evaluate it\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "\n",
    "# Start interactive session\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True))\n",
    "\n",
    "#Load model\n",
    "new_saver = tf.train.import_meta_graph('/tmp/my-model.meta')\n",
    "new_saver.restore(sess, '/tmp/my-model')\n",
    "\n",
    "# Evaluate over the test data\n",
    "print('cross_entropy test', cross_entropy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "print('Accuracy test', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

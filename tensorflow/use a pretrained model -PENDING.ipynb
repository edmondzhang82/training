{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python2.7/site-packages/tensorflow/__init__.pyc\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print tf.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use a pretrained model\n",
    "path_model = '/Users/jorge/tensorflow/tensorflow/models/image/imagenet'\n",
    "\n",
    "\n",
    "#Create graph\n",
    "with tf.gfile.FastGFile(os.path.join(path_model, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print graph_def.ListFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Image data\n",
    "image = os.path.join(path_model, 'cropped_panda.jpg')\n",
    "image_data = tf.gfile.FastGFile(image, 'rb').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00235826e-04   2.51057325e-04   7.98699330e-05 ...,   1.00235244e-04\n",
      "    1.00236299e-04   1.00236299e-04]]\n"
     ]
    }
   ],
   "source": [
    "#Generate predictios from the jpg file\n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                           {'DecodeJpeg/contents:0': image_data})\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = os.path.join(\n",
    "          path_model, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = os.path.join(\n",
    "          path_model, 'imagenet_synset_to_human_label_map.txt')\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "    \n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"Loads a human readable English name for each softmax node.\n",
    "\n",
    "    Args:\n",
    "      label_lookup_path: string UID to integer node ID.\n",
    "      uid_lookup_path: string UID to human-readable string.\n",
    "\n",
    "    Returns:\n",
    "      dict from integer node ID to human-readable string.\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not tf.gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.89233)\n",
      "indri, indris, Indri indri, Indri brevicaudatus (score = 0.00859)\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00264)\n",
      "custard apple (score = 0.00141)\n",
      "earthstar (score = 0.00107)\n"
     ]
    }
   ],
   "source": [
    "# Creates node ID --> English string lookup.\n",
    "node_lookup = NodeLookup()\n",
    "\n",
    "top_k = predictions.argsort()[-5:][::-1]\n",
    "for node_id in top_k:\n",
    "    human_string = node_lookup.id_to_string(node_id)\n",
    "    score = predictions[node_id]\n",
    "    print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.bash_history', '.bash_profile', '.bash_profile-anaconda.bak', '.bash_sessions', '.cache', '.CFUserTextEncoding', '.cmake', '.config', '.continuum', '.cups', '.designer', '.dropbox', '.DS_Store', '.gitconfig', '.ipython', '.jupyter', '.local', '.matplotlib', '.mono', '.oracle_jre_usage', '.profile', '.putty', '.PyCharm50', '.R', '.Rapp.history', '.recently-used', '.Rhistory', '.rnd', '.rstudio-desktop', '.spyder2', '.ssh', '.subversion', '.tblive-4', '.theano', '.theanorc', '.Trash', '.viminfo', '.wget-hsts', '.Xauthority', 'Admin', 'aeat', 'anaconda', 'Applications', 'Biblioteca de calibre', 'caffe', 'Desktop', 'Documents', 'Downloads', 'Dropbox', 'dumps', 'envs', 'Library', 'Movies', 'Music', 'nvidia', 'NVIDIA_CUDA-7.5_Samples', 'oneDrive', 'Pictures', 'projects', 'Public', 'PycharmProjects', 'Reference', 'tensorflow', 'torch', 'VirtualBox VMs', 'working']\n"
     ]
    }
   ],
   "source": [
    "print os.listdir('/Users/jorge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "print ord('1')\n",
    "print chr(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_word(word_char, im_path='/path to curated univenda chars/'):\n",
    "    word_img = np.zeros((64:64*len(word_char)))\n",
    "    character_cuts = []\n",
    "    \n",
    "    pos_fin_prev = 0\n",
    "    for c in word_char:\n",
    "        #Select random char image from the dir of specific character\n",
    "        img_list = os.listdir(im_path + ord(c))\n",
    "        n_img = int(random.uniform(0,len(img_list)))\n",
    "        img_c = plt.imread(im_path + str(ord(c)) + '/' + img_list[n_img])\n",
    "\n",
    "        #Calculate the initial and final positions of the character line by line\n",
    "        pos_ini = np.zeros(img_c.shape[1])\n",
    "        pos_fin = np.zeros(img_c.shape[1])\n",
    "        for row, line in enumerate(img_c):\n",
    "            init_found = False\n",
    "            for column, value in enumerate line:\n",
    "                if not(init_found) and value>0:\n",
    "                    init_found = True\n",
    "                    pos_ini[row] = column\n",
    "                if init_found and value>0:\n",
    "                    pos_fin[row] = column\n",
    "        min_ini = pos_ini.min()\n",
    "        max_fin = pos_fin.max()\n",
    "        len_char = max_fin - min_ini\n",
    "        \n",
    "        #put the new char over the image\n",
    "        word_img[:,pos_fin_prev:pos_fin_prev + len_char] = max( word_img[:,pos_fin_prev:pos_fin_prev + len_char],\n",
    "                                                               img_c[:,min_ini:max_fin])\n",
    "        pos_fin_prev = pos_fin_prev + len_char\n",
    "        character_cuts += [pos_fin_prev + len_char]\n",
    "        \n",
    "        \n",
    "    return word_img, character_cuts\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

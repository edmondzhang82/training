{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word tagging\n",
    "\n",
    "Annotate relevant tags in texts. Example: name entities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf \n",
    "import os \n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "ATIS (Airline Travel Information System) dataset. Available in: https://github.com/mesnilgr/is13/blob/master/data/load.py\n",
    "\n",
    "### Example:\n",
    "\n",
    "Input (words)\tshow\tflights\tfrom\tBoston\tto\tNew\tYork\ttoday\n",
    "\n",
    "Output (labels)\tO\tO\tO\tB-dept\tO\tB-arr\tI-arr\tB-date\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "atis_file = '/Users/jorge/data/training/text/atis/atis.pkl'\n",
    "with open(atis_file,'rb') as f:\n",
    "    #train, test, dicts = pickle.load(f, encoding='bytes') #python3\n",
    "    train, test, dicts = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels2idx', 'tables2idx', 'words2idx']\n"
     ]
    }
   ],
   "source": [
    "print(dicts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / test sets:\n",
    "    - X: list of input sequences\n",
    "    - label: List of target labels asociated to each word in each sentence.\n",
    "## Dictionaries\n",
    "    - labels2idx:  To decode the labels\n",
    "    - words2idx: To decode the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "                               WORD                               LABEL\n",
      "                                  i                                   O\n",
      "                               want                                   O\n",
      "                                 to                                   O\n",
      "                                fly                                   O\n",
      "                               from                                   O\n",
      "                             boston                 B-fromloc.city_name\n",
      "                                 at                                   O\n",
      "                    DIGITDIGITDIGIT                  B-depart_time.time\n",
      "                                 am                  I-depart_time.time\n",
      "                                and                                   O\n",
      "                             arrive                                   O\n",
      "                                 in                                   O\n",
      "                             denver                   B-toloc.city_name\n",
      "                                 at                                   O\n",
      "               DIGITDIGITDIGITDIGIT                  B-arrive_time.time\n",
      "                                 in                                   O\n",
      "                                the                                   O\n",
      "                            morning         B-arrive_time.period_of_day\n",
      "\n",
      "************************************************************\n",
      "\n",
      "                               WORD                               LABEL\n",
      "                               what                                   O\n",
      "                            flights                                   O\n",
      "                                are                                   O\n",
      "                          available                                   O\n",
      "                               from                                   O\n",
      "                         pittsburgh                 B-fromloc.city_name\n",
      "                                 to                                   O\n",
      "                          baltimore                   B-toloc.city_name\n",
      "                                 on                                   O\n",
      "                           thursday              B-depart_date.day_name\n",
      "                            morning         B-depart_time.period_of_day\n",
      "\n",
      "************************************************************\n",
      "\n",
      "test\n",
      "                               WORD                               LABEL\n",
      "                                  i                                   O\n",
      "                              would                                   O\n",
      "                               like                                   O\n",
      "                                 to                                   O\n",
      "                               find                                   O\n",
      "                                  a                                   O\n",
      "                             flight                                   O\n",
      "                               from                                   O\n",
      "                          charlotte                 B-fromloc.city_name\n",
      "                                 to                                   O\n",
      "                                las                   B-toloc.city_name\n",
      "                              vegas                   I-toloc.city_name\n",
      "                               that                                   O\n",
      "                              makes                                   O\n",
      "                                  a                                   O\n",
      "                               stop                                   O\n",
      "                                 in                                   O\n",
      "                                st.                 B-stoploc.city_name\n",
      "                              louis                 I-stoploc.city_name\n",
      "\n",
      "************************************************************\n",
      "\n",
      "                               WORD                               LABEL\n",
      "                                 on                                   O\n",
      "                              april            B-depart_date.month_name\n",
      "                              first            B-depart_date.day_number\n",
      "                                  i                                   O\n",
      "                               need                                   O\n",
      "                                  a                                   O\n",
      "                             ticket                                   O\n",
      "                               from                                   O\n",
      "                             tacoma                 B-fromloc.city_name\n",
      "                                 to                                   O\n",
      "                                san                   B-toloc.city_name\n",
      "                               jose                   I-toloc.city_name\n",
      "                          departing                                   O\n",
      "                             before         B-depart_time.time_relative\n",
      "                              DIGIT                  B-depart_time.time\n",
      "                                 am                  I-depart_time.time\n",
      "\n",
      "************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize data\n",
    "\n",
    "#w2idx, _, labels2idx = dicts['words2idx'], dicts['tables2idx'], dicts['labels2idx']\n",
    "#idx2w  = dict((v,k) for k,v in w2idx.iteritems())\n",
    "#idx2ne = dict((v,k) for k,v in ne2idx.iteritems())\n",
    "#idx2la = dict((v,k) for k,v in labels2idx.iteritems())\n",
    "\n",
    "\n",
    "w2idx, ne2idx, labels2idx = dicts[b'words2idx'], dicts[b'tables2idx'], dicts[b'labels2idx']\n",
    "    \n",
    "idx2w  = dict((v,k) for k,v in w2idx.items())\n",
    "idx2la = dict((v,k) for k,v in labels2idx.items())\n",
    "\n",
    "train_x, _, train_label = train\n",
    "test_x,  _,  test_label  = test\n",
    "wlength = 35\n",
    "\n",
    "for e in ['train','test']:\n",
    "    print(e)\n",
    "    for sw, sl in zip(eval(e+'_x')[:2], eval(e+'_label')[:2]):\n",
    "        print( 'WORD'.rjust(wlength), 'LABEL'.rjust(wlength))\n",
    "        for wx, la in zip(sw, sl): print( idx2w[wx].rjust(wlength), idx2la[la].rjust(wlength))\n",
    "        print( '\\n'+'**'*30+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "---------\n",
      "boston\n",
      "pittsburgh\n",
      "san\n",
      "washington\n",
      "tacoma\n",
      "pittsburgh\n",
      "\n",
      "\n",
      "test\n",
      "---------\n",
      "charlotte\n",
      "tacoma\n",
      "phoenix\n",
      "phoenix\n",
      "orlando\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select words for the label 48: b'B-fromloc.city_name' in train and test to check that are different:\n",
    "for e in ['train','test']:\n",
    "    print(e)\n",
    "    print('---------')\n",
    "    for sw, sl in zip(eval(e+'_x')[:5], eval(e+'_label')[:5]):\n",
    "        for wx, la in zip(sw, sl): \n",
    "            if la==48:\n",
    "                print( idx2w[wx])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "    - Convert the list of sequences of words into an array of words x characteristics.\n",
    "    - The characteristics are the context of the word in the sentence.\n",
    "        - For each word in the sentence, generate the context with the previous and the next words in the sentence.\n",
    "        - For words at the beggining and the end, use padding to complete the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[527, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 527]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_PAD = 527\n",
    "\n",
    "def context(l, size=3):\n",
    "    l = list(l)\n",
    "    lpadded = size // 2 * [ID_PAD] + l + size // 2 * [ID_PAD]\n",
    "    out = [lpadded[i:(i + size)] for i in range(len(l))]\n",
    "    return out\n",
    "\n",
    "x = np.array([0, 1, 2, 3, 4], dtype=np.int32)\n",
    "context(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X trn shape:  (56590, 10)\n",
      "X_tst shape:  (9198, 10)\n"
     ]
    }
   ],
   "source": [
    "X_trn=[]\n",
    "for s in train_x:\n",
    "    X_trn += context(s,size=10)\n",
    "X_trn = np.array(X_trn)\n",
    "\n",
    "X_tst=[]\n",
    "for s in test_x:\n",
    "    X_tst += context(s,size=10)\n",
    "X_tst = np.array(X_tst)\n",
    "\n",
    "print('X trn shape: ', X_trn.shape)\n",
    "print('X_tst shape: ',X_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_trn shape:  (56590,)\n",
      "y_tst shape:  (9198,)\n"
     ]
    }
   ],
   "source": [
    "y_trn=[]\n",
    "for s in train_label:\n",
    "    y_trn += list(s)\n",
    "y_trn = np.array(y_trn)\n",
    "print('y_trn shape: ',y_trn.shape)\n",
    "\n",
    "y_tst=[]\n",
    "for s in test_label:\n",
    "    y_tst += list(s)\n",
    "y_tst = np.array(y_tst)\n",
    "print('y_tst shape: ',y_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels:  121\n",
      "Num words:  572\n"
     ]
    }
   ],
   "source": [
    "print('Num labels: ',len(set(y_trn)))\n",
    "print('Num words: ',len(set(idx2w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model\n",
    "\n",
    "## Architecture\n",
    "    - tf.nn.embedding_lookup\n",
    "    - tf.nn.dynamic_rnn layer\n",
    "    - Dense layer: tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    \n",
    "## Features\n",
    "    - Dropout\n",
    "    - Saver\n",
    "    - Cross entropy with loss regularization\n",
    "    - Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#General parameters\n",
    "LOG_DIR = '/tmp/airline/'\n",
    "\n",
    "# data attributes\n",
    "input_seq_length = X_trn.shape[1]\n",
    "input_vocabulary_size = len(set(idx2w)) + 1\n",
    "output_length = 127\n",
    "\n",
    "#Model parameters\n",
    "embedding_size=64\n",
    "num_hidden_lstm = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save words and labels for embedding visualization\n",
    "with open( os.path.join(LOG_DIR, 'records.tsv'), \"w\") as record_file:\n",
    "    for item in idx2w.items():\n",
    "        record_file.write(item[1].decode('ascii')+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_layer:  Tensor(\"Embeddings/embedding_lookup:0\", shape=(?, 10, 64), dtype=float32)\n",
      "lstm_outputs:  Tensor(\"RNN/rnn1/transpose:0\", shape=(?, 10, 128), dtype=float32)\n",
      "dense_output:  Tensor(\"Dense/Relu:0\", shape=(?, 127), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# Define the tensorflow graph\n",
    "batch_size = 256\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # graph definition\n",
    "    # Inputs\n",
    "    with tf.name_scope('Inputs') as scope:\n",
    "        x = tf.placeholder(tf.int32, shape=[None, input_seq_length], name='x')\n",
    "        y = tf.placeholder(tf.int64, shape=[None], name='y')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    with tf.name_scope('Embeddings') as scope:\n",
    "        W_embedding = tf.Variable(tf.random_uniform([input_vocabulary_size, embedding_size], -1.0, 1.0) ,name=\"W\")\n",
    "        embedding_layer = tf.nn.embedding_lookup(W_embedding, x)\n",
    "        print('embedding_layer: ', embedding_layer)\n",
    "\n",
    "        ## VISUALIZE EMBEDDINGS\n",
    "        # Use the same LOG_DIR where you stored your checkpoint.\n",
    "        summary_writer = tf.train.SummaryWriter(LOG_DIR)\n",
    "\n",
    "        # Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "        config = projector.ProjectorConfig()\n",
    "\n",
    "        # You can add multiple embeddings. Here we add only one.\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = W_embedding.name\n",
    "        # Link this tensor to its metadata file (e.g. labels).\n",
    "        embedding.metadata_path = os.path.join(LOG_DIR, 'records.tsv')\n",
    "\n",
    "        # Saves a configuration file that TensorBoard will read during startup.\n",
    "        projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    with tf.name_scope('RNN') as scope:\n",
    "        cell_1 = tf.nn.rnn_cell.LSTMCell(num_hidden_lstm, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123))\n",
    "        cell_1 = tf.nn.rnn_cell.DropoutWrapper(cell_1, output_keep_prob=keep_prob)\n",
    "        lstm_outputs, lstm_state = tf.nn.dynamic_rnn(cell_1, embedding_layer, dtype=tf.float32, scope='rnn1')\n",
    "        print('lstm_outputs: ', lstm_outputs)\n",
    " \n",
    "\n",
    "    #Dense layer form RNN outs to prediction\n",
    "    with tf.name_scope('Dense') as scope:\n",
    "        W_dense = tf.Variable(tf.truncated_normal([num_hidden_lstm, output_length], stddev=0.1), name='W_dense')\n",
    "        b_dense = tf.Variable(tf.constant(0.1, shape=[output_length]), name='b_dense')\n",
    "        dense_output = tf.nn.relu(tf.matmul(lstm_outputs[:,-1,:], W_dense) + b_dense)\n",
    "        print('dense_output: ', dense_output)\n",
    "\n",
    "        \n",
    "    #Prediction\n",
    "    y_pred = tf.nn.softmax(dense_output, name='y_pred')\n",
    "\n",
    "    # Loss function\n",
    "    with tf.name_scope(\"xent\") as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(dense_output, y, name='cross_entropy')\n",
    "        '''\n",
    "        # Regularize the loss\n",
    "        l2_loss = 0.001 * (tf.nn.l2_loss(W) + tf.nn.l2_loss(W_dense) + tf.nn.l2_loss(b_dense)) \n",
    "        cross_entropy = tf.add(cross_entropy, l2_loss, name='loss')        \n",
    "        '''        \n",
    "        ce_summ = tf.histogram_summary(\"cross entropy\", cross_entropy) #TENSORBOARD\n",
    "\n",
    "\n",
    "    #Optimizer\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        train_op = optimizer.minimize(cross_entropy, name='train_op')\n",
    "\n",
    "\n",
    "    #Accuracy\n",
    "    with tf.name_scope(\"test\") as scope:\n",
    "        correct_prediction = tf.equal(tf.argmax(dense_output,1), y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "        accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy) #TENSORBOARD\n",
    "\n",
    "        \n",
    "    # Create a saver and save weigths.\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[554, 241, 481, 165, 193, 197, 208, 379, 502,  64],\n",
      "       [193, 514, 208,  77, 502, 137, 359, 544,  40, 481],\n",
      "       [232, 331, 237, 358,  13, 193, 208,  77, 502, 137],\n",
      "       [ 32, 194,  40, 183, 208, 137, 502, 415, 205, 527],\n",
      "       [232, 331,  13, 277, 353, 194, 208, 452, 375, 195],\n",
      "       [527, 193, 348, 208, 313, 502, 282,  71, 358, 249],\n",
      "       [193, 208, 128, 502, 415, 205, 527, 527, 527, 527],\n",
      "       [358, 481, 174, 353,  65, 524, 435, 527, 527, 527],\n",
      "       [208, 481,  29, 234, 379, 502, 159, 527, 527, 527],\n",
      "       [527, 527, 527, 439, 301, 481, 194, 208, 415, 205],\n",
      "       [481, 265, 193, 208,  64, 502, 137, 358, 248, 435],\n",
      "       [157,  37,  26, 221, 561,  13, 105, 353, 430, 111],\n",
      "       [534, 358, 481, 190, 105,  37,  26, 193, 208, 376],\n",
      "       [527, 527, 527, 383, 276, 530, 194,  73,  77,  40],\n",
      "       [527, 527, 527, 527, 554, 194,  50, 389,  86,  37],\n",
      "       [481, 193, 501, 481, 321, 358, 530,  26, 200, 426],\n",
      "       [527, 527, 527, 527,  13, 190, 105, 193, 358,  37],\n",
      "       [502, 268, 448, 234, 481, 321, 527, 527, 527, 527],\n",
      "       [ 50, 481, 183, 208, 128, 502, 415, 205, 358, 193],\n",
      "       [527, 527, 527, 527, 527, 383, 212, 217, 512,  62]]), array([126,  78, 126,  48, 126, 126, 123,  27, 126, 126, 126, 126,   2,\n",
      "         2, 126, 126,  18,  33, 126, 126], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "#batch generator\n",
    "def batch_generator(x=X_trn, y=y_trn, batch_size=batch_size):\n",
    "    from sklearn.utils import shuffle\n",
    "    x_shuffle, y_shuffle = shuffle(x, y, random_state=0)\n",
    "    for i in range(0, x.shape[0]-batch_size, batch_size):\n",
    "        x_batch = x_shuffle[i:i+batch_size,:]\n",
    "        y_batch = y_shuffle[i:i+batch_size]\n",
    "        yield x_batch, y_batch\n",
    "    \n",
    "seq = batch_generator(x=X_trn, y=y_trn, batch_size=20)\n",
    "print(next(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "Epoch - Loss(trn) -  Acc(trn)   -   Loss(tst) -   Acc(tst)\n",
      "WARNING:tensorflow:From <ipython-input-19-74a3f477b183>:7 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "0   -   1.91106   -   0.626361   -   1.53324   -   0.632254\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "1   -   1.21519   -   0.719793   -   1.06113   -   0.763951\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-2 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "2   -   0.813426   -   0.815522   -   0.709563   -   0.854241\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-3 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "3   -   0.552627   -   0.87873   -   0.540679   -   0.89375\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "4   -   0.412718   -   0.915583   -   0.433619   -   0.914174\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-5 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "5   -   0.32175   -   0.936192   -   0.37626   -   0.923437\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-6 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "6   -   0.256002   -   0.949024   -   0.306973   -   0.938281\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-7 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "7   -   0.213588   -   0.958763   -   0.283732   -   0.944085\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-8 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "8   -   0.187026   -   0.964526   -   0.268488   -   0.949554\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-9 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "9   -   0.167421   -   0.968008   -   0.247415   -   0.954464\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "10   -   0.147608   -   0.972586   -   0.229579   -   0.95625\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-11 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "11   -   0.13418   -   0.975078   -   0.214952   -   0.960491\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-12 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "12   -   0.12571   -   0.97681   -   0.203937   -   0.962388\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-13 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "13   -   0.11659   -   0.978136   -   0.201808   -   0.964621\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-14 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "14   -   0.10995   -   0.979108   -   0.19545   -   0.964732\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-15 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "15   -   0.0982984   -   0.981865   -   0.208283   -   0.960379\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-16 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "16   -   0.092457   -   0.982448   -   0.199144   -   0.965179\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-17 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "17   -   0.0895424   -   0.982943   -   0.194908   -   0.965737\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-18 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "18   -   0.0861068   -   0.983332   -   0.200763   -   0.96596\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-19 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "19   -   0.0841296   -   0.983968   -   0.199114   -   0.964732\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "20   -   0.0799241   -   0.98411   -   0.20127   -   0.966183\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-21 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "21   -   0.0754674   -   0.985276   -   0.200272   -   0.966406\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-22 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "22   -   0.0735202   -   0.985188   -   0.202092   -   0.966629\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-23 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "23   -   0.0718851   -   0.985895   -   0.19999   -   0.966629\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-24 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "24   -   0.0707513   -   0.985718   -   0.205288   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-25 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "25   -   0.0673023   -   0.98685   -   0.210641   -   0.966295\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-26 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "26   -   0.0667402   -   0.986372   -   0.225577   -   0.963616\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-27 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "27   -   0.0641135   -   0.987221   -   0.232399   -   0.965737\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-28 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "28   -   0.0633644   -   0.987397   -   0.219097   -   0.967299\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-29 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "29   -   0.0601047   -   0.987998   -   0.22308   -   0.966741\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "30   -   0.0603194   -   0.98791   -   0.225729   -   0.966295\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-31 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "31   -   0.0569918   -   0.988105   -   0.237201   -   0.96529\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-32 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "32   -   0.061592   -   0.987115   -   0.236277   -   0.965513\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-33 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "33   -   0.0621579   -   0.986885   -   0.234311   -   0.965513\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-34 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "34   -   0.058012   -   0.988016   -   0.218762   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-35 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "35   -   0.0537048   -   0.989041   -   0.215758   -   0.96808\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-36 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "36   -   0.0529676   -   0.989236   -   0.217889   -   0.965848\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-37 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "37   -   0.0523397   -   0.989024   -   0.24116   -   0.966964\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-38 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "38   -   0.0511388   -   0.989554   -   0.224854   -   0.967522\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-39 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "39   -   0.0518945   -   0.989465   -   0.250635   -   0.964955\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "40   -   0.0563787   -   0.987981   -   0.237295   -   0.966741\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-41 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "41   -   0.0525475   -   0.9892   -   0.225148   -   0.967634\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-42 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "42   -   0.0584076   -   0.988016   -   0.229284   -   0.967188\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-43 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "43   -   0.0509027   -   0.989501   -   0.224039   -   0.96875\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-44 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "44   -   0.0477619   -   0.990296   -   0.229699   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-45 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "45   -   0.0492718   -   0.989572   -   0.238103   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-46 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "46   -   0.0490227   -   0.989837   -   0.235254   -   0.969308\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-47 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "47   -   0.0482946   -   0.989819   -   0.217494   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-48 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "48   -   0.0475847   -   0.989996   -   0.23341   -   0.969308\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "49   -   0.0513096   -   0.989112   -   0.226539   -   0.970089\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "50   -   0.0489292   -   0.98989   -   0.240453   -   0.966741\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-51 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "51   -   0.0500606   -   0.989819   -   0.221838   -   0.970424\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-52 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "52   -   0.0518292   -   0.989218   -   0.225141   -   0.967969\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-53 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "53   -   0.0488249   -   0.989819   -   0.250338   -   0.967411\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-54 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "54   -   0.0498328   -   0.989554   -   0.228916   -   0.969308\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-55 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "55   -   0.0468108   -   0.990155   -   0.237187   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-56 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "56   -   0.044736   -   0.990791   -   0.236022   -   0.970647\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-57 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "57   -   0.0456705   -   0.990473   -   0.239004   -   0.969531\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-58 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "58   -   0.0436932   -   0.990933   -   0.23376   -   0.971205\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-59 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "59   -   0.0469741   -   0.99019   -   0.254632   -   0.967188\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-60 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "60   -   0.0531026   -   0.988847   -   0.239185   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-61 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "61   -   0.0477759   -   0.989996   -   0.235734   -   0.966964\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-62 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "62   -   0.0471659   -   0.990208   -   0.23547   -   0.969754\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-63 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "63   -   0.0450765   -   0.990614   -   0.242223   -   0.968638\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-64 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "64   -   0.0434505   -   0.991039   -   0.238895   -   0.969085\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-65 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "65   -   0.0433705   -   0.990933   -   0.256222   -   0.967634\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-66 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "66   -   0.0441835   -   0.990632   -   0.248897   -   0.968973\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-67 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "67   -   0.0486122   -   0.989607   -   0.255452   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-68 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "68   -   0.0459431   -   0.990208   -   0.261621   -   0.967299\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-69 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "69   -   0.045178   -   0.990614   -   0.240066   -   0.96808\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-70 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "70   -   0.0485335   -   0.989978   -   0.238304   -   0.969085\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-71 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "71   -   0.049496   -   0.989678   -   0.24802   -   0.966964\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-72 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "72   -   0.0486432   -   0.989784   -   0.25461   -   0.969978\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-73 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "73   -   0.0458388   -   0.990508   -   0.24916   -   0.969196\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-74 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "74   -   0.0436652   -   0.990915   -   0.249987   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-75 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "75   -   0.0448094   -   0.99065   -   0.251608   -   0.968973\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-76 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "76   -   0.0442116   -   0.990809   -   0.251709   -   0.969085\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-77 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "77   -   0.043771   -   0.99088   -   0.253361   -   0.968527\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-78 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "78   -   0.0434478   -   0.990862   -   0.250015   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-79 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "79   -   0.0435454   -   0.990915   -   0.27521   -   0.967746\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-80 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "80   -   0.0473159   -   0.989925   -   0.259405   -   0.96942\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-81 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "81   -   0.0463471   -   0.990296   -   0.264046   -   0.967857\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-82 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "82   -   0.0456729   -   0.990402   -   0.250224   -   0.968527\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-83 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "83   -   0.0437663   -   0.991039   -   0.24928   -   0.969754\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-84 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "84   -   0.0446526   -   0.990632   -   0.247673   -   0.967969\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-85 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "85   -   0.0430649   -   0.99095   -   0.241492   -   0.970759\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-86 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "86   -   0.043445   -   0.99088   -   0.263074   -   0.968304\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-87 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "87   -   0.0465644   -   0.990279   -   0.255721   -   0.96808\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-88 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "88   -   0.0454911   -   0.990491   -   0.240311   -   0.969754\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-89 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "89   -   0.0451119   -   0.990561   -   0.242252   -   0.970759\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-90 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "90   -   0.0436795   -   0.990915   -   0.27907   -   0.969754\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-91 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "91   -   0.0441946   -   0.990826   -   0.259743   -   0.969531\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-92 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "92   -   0.0422315   -   0.991233   -   0.261711   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-93 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "93   -   0.0422694   -   0.991145   -   0.263707   -   0.969866\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-94 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "94   -   0.0420767   -   0.99118   -   0.263055   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-95 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "95   -   0.0422777   -   0.991162   -   0.268204   -   0.969308\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-96 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "96   -   0.0431592   -   0.990862   -   0.298257   -   0.966295\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-97 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "97   -   0.0507025   -   0.98943   -   0.243482   -   0.969643\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-98 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "98   -   0.0471991   -   0.990084   -   0.253825   -   0.971763\n",
      "INFO:tensorflow:/tmp/airline/model.ckpt-99 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "99   -   0.0441227   -   0.990773   -   0.278931   -   0.971205\n"
     ]
    }
   ],
   "source": [
    "# Execute the graph to train a network\n",
    "nEpochs = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    print('Initializing')\n",
    "    print('Epoch - Loss(trn) -  Acc(trn)   -   Loss(tst) -   Acc(tst)')\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    for epoch in range(nEpochs):\n",
    "        ce_c=[]\n",
    "        acc_c=[]\n",
    "        ce_c_tst=[]\n",
    "        acc_c_tst=[]\n",
    "        \n",
    "        batch_list = batch_generator(x=X_trn, y=y_trn, batch_size=batch_size)\n",
    "        for i, batch in enumerate(batch_list):\n",
    "            feedDict = {x: batch[0], y: batch[1], keep_prob: 0.5, learning_rate: 0.001} # dictionary of batch data to run the graph\n",
    "            _, ce, acc = session.run([train_op, cross_entropy, accuracy], feed_dict=feedDict)\n",
    "            ce_c += [ce]\n",
    "            acc_c += [acc]\n",
    "            \n",
    "        batch_list_tst = batch_generator(x=X_tst, y=y_tst, batch_size=batch_size)\n",
    "        for x_batch, y_batch in batch_list_tst:\n",
    "            feedDict = {x: x_batch, y: y_batch, keep_prob: 1} # dictionary of batch data to run the graph\n",
    "            ce_tst, acc_tst = session.run([cross_entropy, accuracy], feed_dict=feedDict)\n",
    "            ce_c_tst += [ce_tst]\n",
    "            acc_c_tst += [acc_tst]\n",
    "            \n",
    "        saver.save(session, os.path.join(LOG_DIR, \"model.ckpt\"), epoch)\n",
    "        \n",
    "        print(epoch, np.mean(ce_c), np.mean(acc_c), np.mean(ce_c_tst), np.mean(acc_c_tst), sep='   -   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  i                                   O\n",
      "                               need                                   O\n",
      "                                  a                                   O\n",
      "                           business                                   O\n",
      "                             ticket                                   O\n",
      "                                 in                                   O\n",
      "                                any                                   O\n",
      "                             flight                                   O\n",
      "                               with                                   O\n",
      "                          departure                                   O\n",
      "                               from                                   O\n",
      "                             alaska                 B-fromloc.city_name\n",
      "                                 to                                   O\n",
      "                                las                   B-toloc.city_name\n",
      "                              vegas                   I-toloc.city_name\n",
      "                             monday              B-depart_date.day_name\n",
      "                               with                                   O\n",
      "                          breakfast                  B-meal_description\n"
     ]
    }
   ],
   "source": [
    "# Predict. Score new paragraph \n",
    "\n",
    "#inv_map = {v: k for k, v in my_map.iteritems()} #python2\n",
    "w2idx = {v.decode('ascii'): k for k, v in idx2w.items()} #python3\n",
    "\n",
    "def score_paragraph(paragraph):\n",
    "    #Preprocess data\n",
    "    p_w = paragraph.split()\n",
    "    p_w_c = [w2idx[w] for w in  p_w]\n",
    "    x_score = np.array(context(p_w_c, size=10))\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "\n",
    "        saver.restore(session, os.path.join(LOG_DIR, \"model.ckpt-99\"))\n",
    "        feedDict = {x: x_score, keep_prob: 1} # dictionary of batch data to run the graph\n",
    "        pred_score = session.run(y_pred, feed_dict=feedDict)\n",
    "\n",
    "    response = [idx2la[l] for l in np.argmax(pred_score,axis=1)]\n",
    "    return response\n",
    "\n",
    "\n",
    "paragraph = 'i need a business ticket in any flight with departure from alaska to las vegas monday with breakfast'\n",
    "response = score_paragraph(paragraph)\n",
    "for wx, la in zip(paragraph.split(), response): print( wx.rjust(wlength), la.rjust(wlength))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

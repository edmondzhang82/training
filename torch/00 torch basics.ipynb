{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Write to HDF5 using deepmind/torch-hdf5\n",
    "require 'hdf5'\n",
    "\n",
    "local myFile = hdf5.open('/tmp/sample_torch.h5', 'w')\n",
    "\n",
    "myFile:write('random', torch.rand(5, 5))\n",
    "myFile:write('tensor', torch.Tensor({{1,2,3,4,5},{6,7,8,9,10}}))\n",
    "\n",
    "myFile:close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random:\t 0.3720  0.5532  0.8844  0.7076  0.2407\n",
       " 0.2454  0.3346  0.4899  0.4470  0.2805\n",
       " 0.0007  0.0060  0.8522  0.2028  0.9565\n",
       " 0.0670  0.3155  0.5306  0.3310  0.4846\n",
       " 0.4578  0.4009  0.6855  0.1944  0.9049\n",
       "[torch.DoubleTensor of size 5x5]\n",
       "\n",
       "Tensor:\t  1   2   3   4   5\n",
       "  6   7   8   9  10\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Read from HDF5\n",
    "require 'hdf5'\n",
    "\n",
    "local myFile = hdf5.open('/tmp/sample_torch.h5', 'r')\n",
    "\n",
    "local random = myFile:read('random'):all()\n",
    "tensor = myFile:read('tensor'):all()\n",
    "\n",
    "myFile:close()\n",
    "\n",
    "print('Random:',random)\n",
    "print('Tensor:',tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : 3\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print({{3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "[torch.DoubleTensor of size 1x5x2]\n",
       "\n",
       "(1,.,.) = \n",
       "  0  0  0  0\n",
       "[torch.FloatTensor of size 1x1x4]\n",
       "\n",
       " 4\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       "(1,.,.) = \n",
       "  1  1  1  1  1\n",
       "  1  1  1  1  1\n",
       "[torch.DoubleTensor of size 1x2x5]\n",
       "\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n",
       "A size:\t 1\n",
       " 5\n",
       " 2\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Create tensors\n",
    "a = torch.ones(1,5,2)\n",
    "b = torch.zeros(1,1,4):float()\n",
    "c = torch.Tensor(1,1):fill(4)\n",
    "\n",
    "print(a,b,c)\n",
    "print(a:transpose(2,3))\n",
    "print(a[1][{{2,3}}])\n",
    "print('A size:',a:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define, train and test a network model\n",
    "    1.- Load data\n",
    "    2.- Define and train the network\n",
    "    3.- Test network over new data\n",
    "\n",
    "\n",
    "based on: \n",
    "https://github.com/soumith/cvpr2015/blob/master/Deep%20Learning%20with%20Torch.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Load the data: cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "require 'paths'\n",
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n",
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)\n",
    "print(testset)\n",
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Functions that we need to use the data on the train\n",
    "\n",
    "-- Function to obtain pairs x,y\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "testset.data = testset.data:double()\n",
    "\n",
    "-- Define size function over trainset\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "   59   43   50   68   98\n",
       "   16    0   18   51   88\n",
       "   25   16   49   83  110\n",
       "   33   38   87  106  115\n",
       "   50   59  102  127  124\n",
       "[torch.DoubleTensor of size 1x1x5x5]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  0.2314  0.1686  0.1961  0.2667  0.3843\n",
       "  0.0627  0.0000  0.0706  0.2000  0.3451\n",
       "  0.0980  0.0627  0.1922  0.3255  0.4314\n",
       "  0.1294  0.1490  0.3412  0.4157  0.4510\n",
       "  0.1961  0.2314  0.4000  0.4980  0.4863\n",
       "[torch.DoubleTensor of size 1x1x5x5]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Rescale.  The easy way\n",
    "print(trainset.data[{{1},{1},{1,5},{1,5}}])\n",
    "trainset.data:div(255.0)\n",
    "print(trainset.data[{{1},{1},{1,5},{1,5}}])\n",
    "\n",
    "testset.data:div(255.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Define and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> output]\n",
       "  (1): nn.SpatialConvolution(3 -> 6, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(400)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "  (13): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Net\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Criterions list\n",
    "\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Solver:\n",
    "\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()\n",
    "\n",
    "for epoch = 1,5 do\n",
    "    net:zeroGradParameters()\n",
    "    output = net:forward(input)\n",
    "    output = joiner:forward(output):float()\n",
    "    gradOutputs = output:clone():zero()\n",
    "    ctcCost = cpu_ctc(output, gradOutputs, labels, sizes)\n",
    "    gradOutputs = gradOutputs:resize(nFrames, batchSize, nClasses):double()\n",
    "    gradOutputs = splitter:forward(gradOutputs)    \n",
    "    gradInputs = net:backward(input, gradOutputs)\n",
    "    net:updateParameters(lrnRate)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Train and test on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 2.3025504841089\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 2.2956860769272\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 2.1435543251276\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.9780875407934\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.8503770957351\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 1.8503770957351\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'cunn';\n",
    "net = net:cuda()\n",
    "criterion = criterion:cuda()\n",
    "\n",
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()\n",
    "\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training.\n",
    "\n",
    "trainer:train(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " 0.0257\n",
       " 0.0102\n",
       " 0.1376\n",
       " 0.0497\n",
       " 0.1714\n",
       " 0.0904\n",
       " 0.1071\n",
       " 0.3659\n",
       " 0.0090\n",
       " 0.0330\n",
       "[torch.CudaTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "airplane\t0.025673650205135\t\n",
       "automobile\t0.010195383802056\t\n",
       "bird\t0.13759727776051\t\n",
       "cat\t0.049671798944473\t\n",
       "deer\t0.17140376567841\t\n",
       "dog\t0.090409204363823\t\n",
       "frog\t0.10709649324417\t\n",
       "horse\t0.36590525507927\t\n",
       "ship\t0.0090133212506771\t\n",
       "truck\t0.033033825457096\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Predict one case\n",
    "\n",
    "testset.data = testset.data:cuda()\n",
    "testset.label = testset.label:cuda()\n",
    "\n",
    "\n",
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])\n",
    "print(predicted:exp())\n",
    "\n",
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to intermediate weigths and intermediate results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a network using dp\n",
    "http://dp.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'dp';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dp.Cifar10\n",
       "{\n",
       "  _data_folder : cifar-10-batches-t7\n",
       "  _input_preprocess : \n",
       "    dp.Pipeline\n",
       "    {\n",
       "      _items : \n",
       "        {\n",
       "          1 : \n",
       "            dp.Standardize\n",
       "            {\n",
       "       "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "       _std : FloatTensor - size: 1x3072\n",
       "              _mean : FloatTensor - size: 1x3072\n",
       "              _global_mean : false\n",
       "              _global_std : false\n",
       "              _std_eps : 0.0001\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "  _download_url : http://torch7.s3-website-us-east-1.amazonaws.com/data/cifar10.t7.tgz\n",
       "  _valid_set : \n",
       "    dp.DataSet\n",
       "    {\n",
       "      _inputs : \n",
       "        dp.ImageView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              bchw : \n",
       "                {\n",
       "                  torch.FloatTensor : FloatTensor - size: 10000x3x32x32\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x40e5cf10\n",
       "          _gradOutputs : table: 0x40f7eb78\n",
       "          _put : false\n",
       "          _type : torch.FloatTensor\n",
       "          _view : bchw\n",
       "          _got : false\n",
       "          _modules : \n",
       "            {\n",
       "              bchw : \n",
       "                {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x40e71f00\n",
       "                }\n",
       "            }\n",
       "          _dim : 4\n",
       "          _input : FloatTensor - size: 10000x3x32x32\n",
       "        }\n",
       "      _which_set : valid\n",
       "      _input_shape : bchw\n",
       "      _targets : \n",
       "        dp.ClassView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "               torch.DoubleTensor : DoubleTensor - size: 10000\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x40e69a80\n",
       "          _gradOutputs : table: 0x4109ef68\n",
       "          _type : torch.DoubleTensor\n",
       "          _view : b\n",
       "          _classes : \n",
       "            {\n",
       "              1 : 0\n",
       "              2 : 1\n",
       "              3 : 2\n",
       "              4 : 3\n",
       "              5 : 4\n",
       "              6 : 5\n",
       "              7 : 6\n",
       "              8 : 7\n",
       "              9 : 8\n",
       "              10 : 9\n",
       "            }\n",
       "          _modules : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x415a7bc8\n",
       "                }\n",
       "            }\n",
       "          _dim : 1\n",
       "          _input : DoubleTensor - size: 10000\n",
       "        }\n",
       "      _output_shape : b\n",
       "    }\n",
       "  _test_set : \n",
       "    dp.DataSet\n",
       "    {\n",
       "      _inputs : \n",
       "        dp.ImageView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              bchw : \n",
       "                {\n",
       "                  torch.FloatTensor : FloatTensor - size: 10000x3x32x32\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x40623078\n",
       "          _gradOutputs : table: 0x40212bc8\n",
       "          _put : false\n",
       "          _type : torch.FloatTensor\n",
       "          _view : bchw\n",
       "          _got : false\n",
       "          _modules : \n",
       "            {\n",
       "              bchw : \n",
       "               "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x407129a8\n",
       "                }\n",
       "            }\n",
       "          _dim : 4\n",
       "          _input : FloatTensor - size: 10000x3x32x32\n",
       "        }\n",
       "      _which_set : test\n",
       "      _input_shape : bchw\n",
       "      _targets : \n",
       "        dp.ClassView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "                  torch.DoubleTensor : DoubleTensor - size: 10000\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x404fc870\n",
       "          _gradOutputs : table: 0x4190f660\n",
       "          _type : torch.DoubleTensor\n",
       "          _view : b\n",
       "          _classes : \n",
       "            {\n",
       "              1 : 0\n",
       "              2 : 1\n",
       "              3 : 2\n",
       "              4 : 3\n",
       "              5 : 4\n",
       "              6 : 5\n",
       "              7 : 6\n",
       "              8 : 7\n",
       "              9 : 8\n",
       "              10 : 9\n",
       "            }\n",
       "          _modules : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x410efb80\n",
       "                }\n",
       "            }\n",
       "          _dim : 1\n",
       "          _input : DoubleTensor - size: 10000\n",
       "        }\n",
       "      _output_shape : b\n",
       "    }\n",
       "  _train_set : \n",
       "    dp.DataSet\n",
       "    {\n",
       "      _inputs : \n",
       "        dp.ImageView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              bchw : \n",
       "                {\n",
       "  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "                torch.FloatTensor : FloatTensor - size: 40000x3x32x32\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x40b627a8\n",
       "          _gradOutputs : table: 0x40ec0a48\n",
       "          _put : false\n",
       "          _type : torch.FloatTensor\n",
       "          _view : bchw\n",
       "          _got : false\n",
       "          _modules : \n",
       "            {\n",
       "              bchw : \n",
       "                {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x406ffc50\n",
       "                }\n",
       "            }\n",
       "          _dim : 4\n",
       "          _input : FloatTensor - size: 40000x3x32x32\n",
       "        }\n",
       "      _which_set : train\n",
       "      _input_shape : bchw\n",
       "      _targets : \n",
       "        dp.ClassView\n",
       "        {\n",
       "          _warn : false\n",
       "          _tensors : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "                  torch.DoubleTensor : DoubleTensor - size: 40000\n",
       "                }\n",
       "            }\n",
       "          _module_graph : table: 0x40209c38\n",
       "          _gradOutputs : table: 0x40224f18\n",
       "          _type : torch.DoubleTensor\n",
       "          _view : b\n",
       "          _classes : \n",
       "            {\n",
       "              1 : 0\n",
       "              2 : 1\n",
       "              3 : 2\n",
       "              4 : 3\n",
       "              5 : 4\n",
       "              6 : 5\n",
       "              7 : 6\n",
       "              8 : 7\n",
       "              9 : 8\n",
       "              10 : 9\n",
       "            }\n",
       "          _modules : \n",
       "            {\n",
       "              b : \n",
       "                {\n",
       "                  1 : nn.Identity\n",
       "                  2 : table: 0x404c1600\n",
       "                }\n",
       "            }\n",
       "          _dim : 1\n",
       "    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      _input : DoubleTensor - size: 40000\n",
       "        }\n",
       "      _output_shape : b\n",
       "    }\n",
       "  _scale : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 1\n",
       "    }\n",
       "  args : \n",
       "    {\n",
       "      1 : 0.2\n",
       "      2 : cifar-10-batches-t7\n",
       "      3 : /tmp\n",
       "      5 : http://torch7.s3-website-us-east-1.amazonaws.com/data/cifar10.t7.tgz\n",
       "      6 : true\n",
       "      7 : \n",
       "        {\n",
       "          1 : \n",
       "            dp.Standardize\n",
       "            {\n",
       "              _std : FloatTensor - size: 1x3072\n",
       "              _mean : FloatTensor - size: 1x3072\n",
       "              _global_mean : false\n",
       "              _global_std : false\n",
       "              _std_eps : 0.0001\n",
       "            }\n",
       "        }\n",
       "      usage : +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
       "\u001b[1;35mCifar10\u001b[0m\n",
       "\n",
       "\u001b[0;34m> \u001b[0musage:\n",
       "\u001b[0;36mCifar10{\n",
       "    [valid_ratio = number]              -- proportion of training set to use for cross-validation.  [default = 0.2]\n",
       "    [data_folder = string]              -- name of test_file  [default = cifar-10-batches-t7]\n",
       "    [data_path = string]                -- path to data repository  [default = /tmp]\n",
       "    [scale = table]                     -- bounds to scale the values between\n",
       "    [download_url = string]             -- URL from which to download dataset if not found on disk.  [default = http://torch7.s3-website-us-east-1.amazonaws.com/data/cifar10.t7.tgz]\n",
       "    [load_all = boolean]                -- Load all datasets : train, valid, test.  [default = true]\n",
       "    [input_preprocess = table | dp.Preprocess]-- to be performed on set inputs, measuring statistics (fitting) on the train_set only, and reusing these to preprocess the valid_set and test_set.\n",
       "    [target_preprocess = table | dp.Preprocess]-- to be performed on set targets, measuring statistics (fitting) on the train_set only, and reusing these to preprocess the valid_set and test_set.\n",
       "}\n",
       "\u001b[0m\n",
       "\u001b[0;36mCifar10{data_folder=string, valid_ratio=number}\n",
       "Cifar10(number, ...)\u001b[0m\n",
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
       "      input_preprocess : \n",
       "        {\n",
       "          1 : \n",
       "            dp.Standardize\n",
       "            {\n",
       "              _std : FloatTensor - size: 1x3072\n",
       "              _mean : FloatTensor - size: 1x3072\n",
       "              _global_mean : false\n",
       "              _global_std : false\n",
       "              _std_eps : 0.0001\n",
       "            }\n",
       "        }\n",
       "      download_url : http://torch7.s3-website-us-east-1.amazonaws.com/data/cifar10.t7.tgz\n",
       "      data_path : /tmp\n",
       "      valid_ratio : 0.2\n",
       "      data_folder : cifar-10-batches-t7\n",
       "      load_all : true\n",
       "    }\n",
       "  _valid_ratio : 0.2\n",
       "  _data_path : /tmp\n",
       "}\n",
       "3072\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Load dataset and preprocess it\n",
    "\n",
    "local input_preprocess = {}\n",
    "table.insert(input_preprocess, dp.Standardize())\n",
    "-- table.insert(input_preprocess, dp.ZCA())\n",
    "-- table.insert(input_preprocess, dp.GCN())\n",
    "-- table.insert(input_preprocess, dp.LeCunLCN{progress=true})\n",
    "    \n",
    "ds = dp.Cifar10{data_path = '/tmp', input_preprocess = input_preprocess}\n",
    "\n",
    "print(ds)\n",
    "\n",
    "print(ds:featureSize())  -- inputSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : 0\n",
       "  2 : 1\n",
       "  3 : 2\n",
       "  4 : 3\n",
       "  5 : 4\n",
       "  6 : 5\n",
       "  7 : 6\n",
       "  8 : 7\n",
       "  9 : 8\n",
       "  10 : 9\n",
       "}\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds:classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Define the model\n",
    "require 'nn';\n",
    "\n",
    "net = nn.Sequential()\n",
    "net:add(nn.Convert(ds:ioShapes(), 'bf')) -- to batchSize x nFeature (also type converts)\n",
    "\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- PENDING TO FINISH\n",
    "\n",
    "-- Define AdaptiveDecay\n",
    "opt.maxWait = 4\n",
    "opt.decayFactor = 0.001\n",
    "ad = dp.AdaptiveDecay{max_wait = opt.maxWait, decay_factor=opt.decayFactor}\n",
    "\n",
    "\n",
    "\n",
    "-- Define the optimizer\n",
    "opt.batchSize = 32\n",
    "--opt.accUpdate = \n",
    "opt.learningRate = 0.1\n",
    "opt.minLR = 0.00001\n",
    "opt.momentum = 0\n",
    "opt.maxOutNorm = 1\n",
    "\n",
    "train = dp.Optimizer{\n",
    "   acc_update = opt.accUpdate,\n",
    "    \n",
    "   loss = nn.ModuleCriterion(nn.ClassNLLCriterion(), nil, nn.Convert()),\n",
    "    \n",
    "   epoch_callback = function(model, report) -- called every epoch\n",
    "      -- learning rate decay\n",
    "      if report.epoch > 0 then\n",
    "         if opt.lrDecay == 'adaptive' then\n",
    "            opt.learningRate = opt.learningRate*ad.decay\n",
    "            ad.decay = 1\n",
    "         end\n",
    "         opt.learningRate = math.max(opt.minLR, opt.learningRate)\n",
    "         print(\"learningRate\", opt.learningRate)\n",
    "      end\n",
    "   end,\n",
    "        \n",
    "   callback = function(model, report) -- called every batch\n",
    "      if opt.accUpdate then\n",
    "         model:accUpdateGradParameters(model.dpnn_input, model.output, opt.learningRate)\n",
    "      else\n",
    "         model:updateGradParameters(opt.momentum) -- affects gradParams\n",
    "         model:updateParameters(opt.learningRate) -- affects params\n",
    "      end\n",
    "      model:maxParamNorm(opt.maxOutNorm) -- affects params\n",
    "      model:zeroGradParameters() -- affects gradParams \n",
    "   end,\n",
    "        \n",
    "   feedback = dp.Confusion(),\n",
    "        \n",
    "   sampler = dp.ShuffleSampler{batch_size = opt.batchSize},\n",
    "        \n",
    "   progress = opt.progress\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Define the evaluators\n",
    "valid = dp.Evaluator{\n",
    "   feedback = dp.Confusion(),  \n",
    "   sampler = dp.Sampler{batch_size = opt.batchSize}\n",
    "}\n",
    "test = dp.Evaluator{\n",
    "   feedback = dp.Confusion(),\n",
    "   sampler = dp.Sampler{batch_size = opt.batchSize}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(400)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "  (13): nn.SoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.SoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0973\n",
       " 0.0901\n",
       " 0.0976\n",
       " 0.1062\n",
       " 0.0981\n",
       " 0.1032\n",
       " 0.1102\n",
       " 0.0920\n",
       " 0.0948\n",
       " 0.1104\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 32\n",
       " 32\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.ones(1,32,32)\n",
    "output = net:forward(input)\n",
    "print(output)\n",
    "\n",
    "net:zeroGradParameters()\n",
    "\n",
    "gradInput = net:backward(input, torch.rand(10))\n",
    "print(#gradInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
